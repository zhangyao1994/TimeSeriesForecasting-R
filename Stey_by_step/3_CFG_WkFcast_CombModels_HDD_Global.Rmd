---
title: "IRIS HDD Forecasting for each CFG Globally"
author: "Yao"
date: "June 12-13, 2018"
output: html_document
---

This is the parallel function version using weekly data and different models, including TBATS, Prophet, ARIMA, lm, and Random Forest, to forecast one quarter HDD demand, and then compare my forecasting All_fcast to MRP.
Update on 7/23/2018.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
options(scipen = 999)
library(lubridate)

# Load egboost relevant libraries
library(quantmod); library(TTR); library(xgboost);

# Load timetk package
library(tidyquant)
library(timetk)
library(broom)

# Random Forest
library(party)
library(randomForest)

# Load TBATS package, as well as for ARIMA
library(forecast)

# Load Facebook Prophet package
library(Rcpp)
library(prophet)

library(scales) # for percent

# make the code parallel using 'parallel' package
library(iterators)
library(parallel)
library(foreach)
library(doParallel)

# faster data format
library(feather)
 
# Calculate the number of cores
no_cores <- detectCores() - 1
registerDoParallel(no_cores)
```

## IRIS HDD Weekly Demand Forecasting for each CFG

```{r load the data}
hdd_qty <- read_feather("~/Yao_Rdata/HDD_QTY_IRIS.feather")

# Weekly data
hdd_qty %>% group_by(CFG,Fiscal_Wk_End_Date,Fiscal_Wk) %>%
  summarise(HDD_QTY = sum(PART_QTY)) -> HDD_Weekly
```

```{r Forecast Function}
myforecast <- function(temp_data){
  df <- data.frame(ds = temp_data$date, y = temp_data$HDD_QTY)
  n <- nrow(df)
  
  # Split into training and test sets
  train <- df %>% filter(ds < '2018-03-23') # No time ahead
  test <- df %>% filter(ds >= '2018-03-23')
  
  WeekAhead <- 0  # no time ahead
  forecastPeriodLen <- 24 + WeekAhead # predict the next half year if possible
  
  if (nrow(test)<1 | nrow(train)<2){
    return(c(CFGgroups[i_CFG],rep(NA,forecastPeriodLen+1)))
  }
  
  # Add time series signature
  train_augmented <- train[nrow(train),] %>%
    tk_augment_timeseries_signature()

  HDD.ts <- ts(train$y,frequency=365.25/7, end = train_augmented$year+train_augmented$yday/365.25)
  
  # TBATS
  fit <- tbats(HDD.ts)
  fcast <- forecast(fit,h=forecastPeriodLen)
  TBATS_fcast <- c(CFGgroups[i_CFG],'TBATS',fcast$mean)
  
  # ARIMA
  if (i_CFG %in% c(11,55,87,94)){
    ARIMA_fcast <- (c(CFGgroups[i_CFG],'ARIMA',rep(NA,forecastPeriodLen)))
  } else {
    fit <- auto.arima(HDD.ts) # Some might fail
    fcast <- forecast(fit,h=forecastPeriodLen)
    ARIMA_fcast <- c(CFGgroups[i_CFG],'ARIMA',fcast$mean)
  }
  
  # Prophet
  m <- prophet(train)
  future <- make_future_dataframe(m, periods = forecastPeriodLen, freq = 'week',include_history = FALSE)
  fcast <- predict(m, future)
  Prophet_fcast <- c(CFGgroups[i_CFG],'Prophet',fcast$yhat)
  
  # lm
  # Add time series signature
  train_augmented <- train %>%
    tk_augment_timeseries_signature()
  # maunually drop unvalid variables
  temp <-
    train_augmented %>% select(-wday.lbl,-month.lbl,-diff)
  # Remove the column with only one value
  if (nrow(temp)>1) {
    temp <- Filter(function(x)(length(unique(x))>1), temp)
  }
  
  # Model using the augmented features
  fit <- lm(y ~ ., data = na.omit(temp))
  # We need to again augment the time series signature to the test set.
  test_augmented <- test %>%
    tk_augment_timeseries_signature()
  yhat_test <- predict(fit, newdata = test_augmented)
  AvailableWeek <- nrow(test)# Remember to update this if the IRIS data is updated
  lm_fcast <- c(CFGgroups[i_CFG],'timetk_lm',rep(NA,WeekAhead),yhat_test,rep(NA,forecastPeriodLen-WeekAhead-AvailableWeek))
  
  # Random Forest
  # Model using the augmented features
  fit <- randomForest(y ~ ., data = na.omit(temp))
  yhat_test <- predict(fit, newdata = test_augmented)
  RF_fcast <- c(CFGgroups[i_CFG],'timetk_RF',rep(NA,WeekAhead),yhat_test,rep(NA,forecastPeriodLen-WeekAhead-AvailableWeek))
  
  # Xgboost
  # Train the xgboost model using the "xgboost" function
  dtrain = xgb.DMatrix(data = as.matrix(select(temp,-y,-ds)), label = temp$y)
  xgModel = xgboost(data = dtrain, nrounds = ceiling(sqrt(nrow(dtrain)))) # sqrt(nrow(dtrain)), I guess
  # Make the predictions on the test data
  temp_test <- test_augmented[,colnames(temp)]
  preds = predict(xgModel, as.matrix(select(temp_test,-y,-ds)))
  Xgboost_fcast <- c(CFGgroups[i_CFG],'timetk_Xgboost',rep(NA,WeekAhead),preds,rep(NA,forecastPeriodLen-WeekAhead-AvailableWeek))
  
  return(rbind(TBATS_fcast,ARIMA_fcast,Prophet_fcast,lm_fcast,RF_fcast,Xgboost_fcast))
}
```


```{r Run the fuctions parallel}
HDD_Weekly$date <- ymd(HDD_Weekly$Fiscal_Wk_End_Date)
CFGgroups <- levels(factor(HDD_Weekly$CFG))
len <- length(CFGgroups)

Comb_fcast <- foreach(i_CFG=1:len, .combine=rbind, .packages=c('tidyverse','forecast','Rcpp','ggthemes','lubridate','tidyquant','timetk','prophet','randomForest','party','quantmod','TTR','xgboost')) %dopar% {
    # Forecast for each CFG
    temp_data <- HDD_Weekly %>% filter(CFG==CFGgroups[i_CFG])
    oneCFG_fcast <- myforecast(temp_data)
    oneCFG_fcast
  }

## by week
weekNames <- c(sprintf("FY19W0%d", 7:9),sprintf("FY19W%d", 10:30))

dimnames(Comb_fcast)[[2]] <- c('CFG','Model',as.character(weekNames))
Comb_fcast <- data.frame(Comb_fcast)
Comb_fcast[,3:ncol(Comb_fcast)] <- lapply(Comb_fcast[,3:ncol(Comb_fcast)], function(x) as.numeric(as.character(x)))

num_CFG_valid <- nrow(Comb_fcast)/6 # The total number of CFGs were forecasted.

Comb_fcast %>% gather(key='Fiscal_Wk',value='HDD_QTY',FY19W07:FY19W30) -> All_fcast

# For plot, do not delete the NA for now.
write_feather(All_fcast, '~/Yao_Rdata/All_fcast_Global.feather') # my_data <- readRDS(file)
```

```{r close the clusters}
# for Parallel package
stopImplicitCluster()
```
