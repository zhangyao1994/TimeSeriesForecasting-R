---
title: "HDD Forecast compared to MRP"
author: "Yao"
date: "Jul 30, 2018"
output: html_document
---

Updated on 07/30/2018.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(feather)
options(scipen = 999)
```

## Load Database from SQL Server

```{r ConnectDB}
library(DBI)
db = dbConnect(odbc::odbc(),
               driver = 'SQL Server',
               server = 'IRISAGL01.aus.amer.dell.com',
               user = 'Yao_Z',
               password = 'y67uhgt$Y')
```

Download the latest HDD sales data from SQL server.

```{sql hdd_qty, connection=db, output.var = 'hdd_qty'}
SELECT 
  D.Cfg_Desc AS CFG, D.sku_num, D.Sample_DPN, C.Fiscal_Qtr, C.Fiscal_Mo, C.Fiscal_Wk, C.Fiscal_Wk_End_Date, C.Fiscal_Date, C.Fiscal_Yr, B.Order_Date_week, C.Fiscal_Mo_End_Date,  C.Fiscal_Qtr_End_Date,
  CASE WHEN A.LOB_DESC = 'PowerEdge' AND A.ESI_order_flag = 'Y' THEN 'PowerEdge - ESI'
                     WHEN A.MGMT_PROD_LVL_3_NM = 'Storage' AND A.DELL_EMC_ORDER_FLAG = 'DELL' THEN 'Storage - DELL'
                ELSE A.LOB_DESC END AS LOB_DESC, A.BRAND_CATG_DESC, 
  A.RGN_DESC,
  A.GBL_PARNT_ACCT_NM AS Customer, 
  SUM(SYS_QTY_DELL) AS SYS_QTY,
  SUM(ITM_QTY) AS PART_QTY
FROM IRIS.[Base].[ISG_Business_Transformation.isgOrders] AS A 
JOIN IRIS.[Base].[ISG_Business_Transformation.isgOrdersDetails] B
ON A.ORD_NBR = B.ORD_NBR AND A.FMLY_PFOLIO_DESC = B.FMLY_PFOLIO_DESC AND A.SRC_BU_ID = B.SRC_BU_ID
JOIN IRIS.DIM.Date C
ON B.ORD_DT = C.Fiscal_Date
JOIN IRIS_Data_Mart.[dbo].[SKU_CFG_Bridge] D
ON B.ITM_NBR = D.sku_num
WHERE D.Cfg_Desc LIKE '%HDD%' AND Commodity_Desc IN ('Hard Drive', 'Controller Cards/HBA') AND A.DELL_EMC_ORDER_FLAG = 'DELL' AND (A.LOB_DESC IN ('PowerEdge','Cloud Products') OR A.MGMT_PROD_LVL_3_NM = 'Storage') ---AND C.Fiscal_Yr >= 'FY16'
GROUP BY
  D.Cfg_Desc, D.sku_num, D.Sample_DPN, C.Fiscal_Qtr, C.Fiscal_Mo, C.Fiscal_Wk, C.Fiscal_Wk_End_Date, C.Fiscal_Date, C.Fiscal_Yr, B.Order_Date_week, C.Fiscal_Mo_End_Date,  C.Fiscal_Qtr_End_Date,
  CASE WHEN A.LOB_DESC = 'PowerEdge' AND A.ESI_order_flag = 'Y' THEN 'PowerEdge - ESI'
                   WHEN A.MGMT_PROD_LVL_3_NM = 'Storage' AND A.DELL_EMC_ORDER_FLAG = 'DELL' THEN 'Storage - DELL'
                   ELSE A.LOB_DESC END, A.BRAND_CATG_DESC, 
  A.RGN_DESC, A.GBL_PARNT_ACCT_NM
ORDER BY D.Cfg_Desc, C.Fiscal_Qtr, C.Fiscal_Mo, C.Fiscal_Wk
```


```{r Deal with missing data}
Weekly_HDD_QTY_combined <- hdd_qty %>% group_by(Order_Date_week,Fiscal_Wk) %>% summarise(Fiscal_Wk_QTY=sum(PART_QTY))
# 7/20/2018 128 weeks

apply(hdd_qty, 2, function(x) any(is.na(x)))

# Columns have NA: Customer
hdd_qty = hdd_qty %>% 
  mutate(Customer = ifelse(
    grepl('Dummy|disti|\032|APPOINTED|ACCT-R', Customer, ignore.case = T) | Customer == '' | is.na(Customer),
    'Unknown_Customer', Customer
  ))

apply(hdd_qty, 2, function(x) any(is.na(x)))
# All NAs have been cleaned.

write_feather(hdd_qty,'~/Yao_Rdata/HDD_QTY_IRIS.feather')
```

Download the latest versions of MRP data.

```{sql connection=db, output.var = 'mrp_data0'}
SELECT [VERSION], MONWKYR, CFG, REGION, SUM(DATA) AS MRP_CT, Commodity_Desc
FROM IRIS.Base.MRP_Weekly A
JOIN IRIS.DIM.DPN B 
ON A.PART = B.DPN
WHERE B.CFG LIKE '%HDD%' AND B.Commodity_Desc IN ('Hard Drive')--Verified with other restrictions. Good for now.
GROUP BY [VERSION], MONWKYR, CFG, REGION, Commodity_Desc
```

```{r Save and read mrp_HDD data}
write_feather(mrp_data0,'~/Yao_Rdata/mrp_HDD.feather')

mrp_data0 <- read_feather('~/Yao_Rdata/mrp_HDD.feather')
```

The MONWKYR in MRP data are actually Calendar Month, Fiscal Week, and Fiscal Year.

```{r Use the Hyperion_Calendar_Mapping to map the MRP MONWKYR to Fiscal Calendar}
# Hyperion_Calendar_Mapping.xlsx
library(readxl)
Hyperion_Calendar_Mapping <- read_excel("~/Yao_Rdata/Hyperion_Calendar_Mapping.xlsx")
mrp_data0 %>% left_join(unique(select(Hyperion_Calendar_Mapping,-Fiscal_Date)),by=c('MONWKYR'='Hyperion_Wk_MONWKYR')) -> mrp_data.calr_mapped

write_feather(mrp_data.calr_mapped,'~/Yao_Rdata/mrp_HDD_caldr_mapped.feather')
```

Read the mapped mrp_data.

```{r Read the mapped mrp_data}
mrp_data.calr_mapped <- read_feather('~/Yao_Rdata/mrp_HDD_caldr_mapped.feather')
```

```{r plot overall HDD_QTY and mrp_data}
HDD_data <- read_feather('~/Yao_Rdata/HDD_QTY_IRIS.feather')
# Check the available data
LastWk <- tail(unique(HDD_data$Fiscal_Wk), n=1)
LastMon <- tail(unique(HDD_data$Fiscal_Mo), n=1)
LastQtr <- tail(unique(HDD_data$Fiscal_Qtr), n=1)

# HDD Weekly Sales
week_data <- HDD_data %>% group_by(Fiscal_Wk) %>%
  summarise(Fiscal_Wk_QTY=sum(PART_QTY))
week_data$VERSION <- 'Historical'

week_mrp <- mrp_data.calr_mapped %>% group_by(VERSION,Fiscal_Wk) %>%
  summarise(Fiscal_Wk_MRP=sum(MRP_CT))

week_data.2 <- week_data %>% full_join(week_mrp) %>%
  gather(Source,HDD_QTY,Fiscal_Wk_QTY,Fiscal_Wk_MRP)
week_data.2$Source <- as.factor(week_data.2$Source)
levels(week_data.2$Source) <- c('MRP','Actual')

# HDD Monthly Sales
month_data <- HDD_data %>% group_by(Fiscal_Mo) %>%
  summarise(Fiscal_Mo_QTY=sum(PART_QTY)) #%>% 
month_data$VERSION <- 'Historical'

month_mrp <- mrp_data.calr_mapped %>% group_by(VERSION,Fiscal_Mo) %>%
  summarise(Fiscal_Mo_MRP=sum(MRP_CT))

month_data.2 <- month_data %>% full_join(month_mrp) %>%
  gather(Source,HDD_QTY,Fiscal_Mo_QTY,Fiscal_Mo_MRP)
month_data.2$Source <- as.factor(month_data.2$Source)
levels(month_data.2$Source) <- c('MRP','Actual')

# HDD Quarterly Sales
quarter_data <- HDD_data %>% group_by(Fiscal_Qtr) %>%
  summarise(Fiscal_Qtr_QTY=sum(PART_QTY)) #%>%
quarter_data$VERSION <- 'Historical'

quarter_mrp <- mrp_data.calr_mapped %>% group_by(VERSION,Fiscal_Qtr) %>%
  summarise(Fiscal_Qtr_MRP=sum(MRP_CT))

quarter_data.2 <- quarter_data %>% full_join(quarter_mrp) %>%
  gather(Source,HDD_QTY,Fiscal_Qtr_QTY,Fiscal_Qtr_MRP)
quarter_data.2$Source <- as.factor(quarter_data.2$Source)
levels(quarter_data.2$Source) <- c('MRP','Actual')
 
# Plot separately but fix the axis range
p_week <- week_data.2 %>%
  ggplot(aes(x=Fiscal_Wk,y=HDD_QTY,group=interaction(Source,VERSION,drop = TRUE),color=interaction(Source,VERSION,drop = TRUE))) +
  geom_point(size = 2) +
  geom_line(size = 1.5) +
  labs(title = 'Overall HDD Weekly Sales and MRP Forecast', x = "Fiscal Week", y = "Part Quantity") + 
  theme_minimal(base_size = 18) + 
  scale_color_tableau('tableau20',name='Data Source and Version') + 
  scale_x_discrete(breaks = c('FY17W01', 'FY18W01', 'FY19W01','FY20W01')) +
  theme(legend.position = 'bottom',plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(label=comma) + expand_limits(y = 0) #+ coord_cartesian(ylim = c(0,2100000))
ggplotly(p_week)
# MRP forecast results are crazy! The truth is that the planning team tends to overestimate first and then leave the rest for the rest of the period. This is a strategy.

p_month <- month_data.2 %>%
  ggplot(aes(x=Fiscal_Mo,y=HDD_QTY,group=interaction(Source,VERSION,drop = TRUE),color=interaction(Source,VERSION,drop = TRUE))) +
  geom_point(size = 2) +
  geom_line(size = 1.5) +
  labs(title = 'Overall HDD Monthly Sales and MRP Forecast', x = "Fiscal Month", y = "Part Quantity") + 
  theme_minimal(base_size = 18) + 
  scale_color_tableau('tableau20',name='Data Source and Version') + 
  scale_x_discrete(breaks = c('FY17M01','FY18M01', 'FY19M01','FY20M01')) +
  theme(legend.position = 'bottom',plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(label=comma) + expand_limits(y = 0) + #coord_cartesian(ylim = c(0,2100000)) +
  geom_vline(xintercept = seq(3,39,3), linetype="dashed", color = 'gray')
ggplotly(p_month)

p_quarter <- quarter_data.2 %>%
  ggplot(aes(x=Fiscal_Qtr,y=HDD_QTY,group=interaction(Source,VERSION,drop = TRUE),color=interaction(Source,VERSION,drop = TRUE))) +
  geom_point(size = 2) +
  geom_line(size = 1.5) +
  labs(title = 'Overall HDD Quarterly Sales and MRP Forecast', x = "Fiscal Quarter", y = "Part Quantity") + 
  theme_minimal(base_size = 14) + 
  scale_color_tableau('tableau20',name='Data Source and Version') + 
  #scale_x_discrete(breaks = c('FY17Q1', 'FY18Q1', 'FY19Q1')) +
  theme(legend.position = 'bottom',plot.title = element_text(hjust = 0.5))+
  scale_y_continuous(label=comma) + expand_limits(y = 0) #+ coord_cartesian(ylim = c(0,2100000))
ggplotly(p_quarter)
```

To create clusters, I will use Region and Volume to classify CFGs. I thought that the "Small and medium" are more stable so that it could be easier to forecast. Actually, "strategic and large" groups have lower errors. This is because that it is easier to forcast large volume compared to low volume.

```{r By Region and Volume}
temp_data <- HDD_data %>% 
  group_by(CFG,RGN_DESC,Fiscal_Qtr) %>%
  summarise(CFG_RGN_Qtr_QTY=sum(PART_QTY)) %>%
  filter(Fiscal_Qtr<'FY19Q2')

temp_data %>% ungroup() %>%
  group_by(CFG,RGN_DESC) %>%
   summarise(Avg_Qtr_HDD_QTY = sum(CFG_RGN_Qtr_QTY)/n_distinct(Fiscal_Qtr)) %>% 
  mutate(HDD_Volume_Group = case_when(
    Avg_Qtr_HDD_QTY <= 100 ~ 'Small',
    Avg_Qtr_HDD_QTY > 100 & Avg_Qtr_HDD_QTY <= 1000 ~ 'Medium',
    Avg_Qtr_HDD_QTY > 1000 & Avg_Qtr_HDD_QTY <= 10000 ~ 'Large',
    Avg_Qtr_HDD_QTY > 10000 ~ 'Strategic'
  )) -> data.grouped

temp_data %>% left_join(data.grouped) -> data.joined

data.joined %>%
  group_by(RGN_DESC,HDD_Volume_Group,Fiscal_Qtr) %>%
  summarise(RGN_Vol_Qtr_QTY=sum(CFG_RGN_Qtr_QTY)) -> data.4plot
  
# HDD Quarterly Sales by Region and Volumne
p <- data.4plot %>%
  ggplot(aes(x=Fiscal_Qtr,y=RGN_Vol_Qtr_QTY,group=HDD_Volume_Group, colour=HDD_Volume_Group)) +
  geom_point(size = 2) +
  geom_line(size = 1.5) +
  labs(title = paste('Overall HDD Quarterly Sales by Region and Volume FY17Q1-',LastQtr, sep = ""), x = "Fiscal Quarter", y = "Part Quantity") + 
  theme_minimal(base_size = 14) + 
  scale_color_tableau('tableau10medium') + 
  scale_x_discrete(breaks = c('FY17Q1', 'FY18Q1', 'FY19Q1')) +
  theme(legend.position = 'bottom',plot.title = element_text(hjust = 0.5))+
  scale_y_continuous(label=comma) + expand_limits(y = 0) +
  facet_wrap(~RGN_DESC)
ggplotly(p)
```

```{r Plot Selected CFG}
# <10%
week_data.selected.lowErr <- HDD_data %>% filter(CFG %in% c('ESG_HDD_SAS12G_4TB_7_2K_3_5','ESG_HDD_SAS6G_600GB_10K_2_5','ESG_HDD_SAS12G_FIPS140_600GB_15K_2_5')) %>%
  group_by(CFG,Fiscal_Wk) %>%
  summarise(Fiscal_Wk_QTY=sum(PART_QTY))
week_data.selected.lowErr$group <- 'LowErr'

# >100%
week_data.selected.highErr <- HDD_data %>% filter(CFG %in% c('ESG_HDD_SAS6G_600GB_15K_2_5','HDD_250GB_SATA_ESG_7_2K_2_5','ESG_HDD_SAS12G_ISE_1TB_7_2K_3_5')) %>%
  group_by(CFG,Fiscal_Wk) %>%
  summarise(Fiscal_Wk_QTY=sum(PART_QTY))
week_data.selected.highErr$group <- 'HighErr'

week_data.selected <- rbind(week_data.selected.lowErr,week_data.selected.highErr)

week_data.selected %>% group_by(CFG,group) %>% 
  summarise(ave_wk=mean(Fiscal_Wk_QTY)) %>%
  arrange(group) -> temp_mean

week_data.selected %>% group_by(CFG,group) %>% 
  summarise(sd_QTY_wk=sd(Fiscal_Wk_QTY)) %>%
  arrange(group) -> temp_sd

p_week <- week_data.selected %>%
  ggplot(aes(x=Fiscal_Wk,y=Fiscal_Wk_QTY,group=CFG,color=group)) +
  geom_point(size = 2) +
  geom_line(size = 1.5) +
  labs(title = 'HDD Weekly Sales with Different Forecast Errors', x = "Fiscal Week", y = "Part Quantity") + 
  theme_minimal(base_size = 18) + 
  scale_color_tableau('tableau10medium') + 
  scale_x_discrete(breaks = c('FY17W01', 'FY18W01', 'FY19W01','FY20W01')) +
  theme(legend.position = 'bottom',plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(label=comma) + expand_limits(y = 0) #+ coord_cartesian(ylim = c(0,2100000))
ggplotly(p_week)
```

