---
title: "HDD Forecast Results Evaluation by Region"
author: "Yao"
date: "June 8-29, 2018"
output: html_document
---

Updated on 06/29/2018
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning=FALSE,message=FALSE)
library(tidyverse)
library(ggthemes)
options(scipen = 999)
library(lubridate)
library(tidyquant)
library(plotly)

library(scales) # for percent

# make the code parallel using 'parallel' package
library(iterators)
library(parallel)
library(foreach)
library(doParallel)

# Calculate the number of cores
no_cores <- detectCores() - 1
registerDoParallel(no_cores)

# fast data format
library(feather)
```

## My models compared to MRP

```{r load the data, eval=FALSE, include=FALSE}
# This chunk was run once, and then done.
# MRP
Fcast_MRP <- read.csv('~/Yao_Excels/HDD_FY19_MRP.csv') 
# remove '_CFG' for MRP
Fcast_MRP$CFG = as.factor(substr(Fcast_MRP$CFG,1,nchar(as.character(Fcast_MRP$CFG))-4))

# All mine
Fcast_Yao <- read_feather('~/Yao_Rdata/All_fcast.feather')

# HDD data from IRIS
hdd_qty <- read_feather("~/Yao_Rdata/HDD_QTY_IRIS.feather")
hdd_qty$CFG <- as.factor(hdd_qty$CFG)
hdd_qty$Region <- as.factor(hdd_qty$RGN_DESC)

# Check the existing regions and make them match each other
# unique(hdd_qty$RGN_DESC)
# unique(Fcast_MRP$Region)
# unique(Fcast_Yao$Region)
Fcast_MRP.Americas <- filter(Fcast_MRP,Region=='AMF')
Fcast_MRP.Americas$Region <- as.factor('Americas')
Fcast_MRP <- rbind(Fcast_MRP.Americas,filter(Fcast_MRP,Region=='APJ'|Region=='EMEA'))
rm(Fcast_MRP.Americas)
```

```{r Match CFG names, eval=FALSE, include=FALSE}
# This chunk was run once, and then done.
# Weekly data from IRIS data
hdd_qty %>% group_by(CFG, Region, Fiscal_Wk) %>%
  summarise(HDD_QTY = sum(PART_QTY)) %>%
  gather(Model,HDD_QTY,HDD_QTY)-> HDD_Weekly

# Weekly data from MRP
Fcast_MRP %>% group_by(CFG, Region, Fiscal_Wk) %>%
  summarise(MRP_Fcast = sum(value)) %>%
  gather(Model,HDD_QTY,MRP_Fcast)-> HDD_Weekly_MRP

# join
HDD_Weekly %>% full_join(HDD_Weekly_MRP) %>% 
  full_join(Fcast_Yao) -> CFG_fcast.joined
rm(HDD_Weekly,HDD_Weekly_MRP,hdd_qty,Fcast_MRP,Fcast_Yao)

write_feather(CFG_fcast.joined, "~/Yao_Rdata/CFG_fcast.feather")
```

```{r Load feather data}
# Load feather data
CFG_fcast.joined <- read_feather("~/Yao_Rdata/CFG_fcast.feather")
CFG_RGN_QTR_data.grouped <- read_feather("~/Yao_Rdata/CFG_RGN_Qtr_grouped.feather")
# Add a columne w: weight # The sum of w is 1.#
Total_Avg_Qtr_HDD_QTY <- sum(CFG_RGN_QTR_data.grouped$Avg_Qtr_HDD_QTY)
CFG_RGN_QTR_data.grouped$w <- CFG_RGN_QTR_data.grouped$Avg_Qtr_HDD_QTY/Total_Avg_Qtr_HDD_QTY
```


```{r Visualize HDD_QTY and Forecast MRP}
# Get all CFG names, all Region names, and all Model names
CFGgroups <- levels(factor(CFG_fcast.joined$CFG))
len_CFG <- length(CFGgroups)
Region.groups <- levels(factor(CFG_fcast.joined$Region))
len_Region <- length(Region.groups)
Model.groups <- levels(factor(CFG_fcast.joined$Model))

# less than 0 means no forecast
# CFG_fcast.joined$HDD_QTY[CFG_fcast.joined$HDD_QTY <= 0] <- NA

l_ggplotly <- htmltools::tagList()
# For each CFG
for (i_CFG in 1:len_CFG) {
  # For each Region
  for (i_Region in 1:len_Region){
    # HDD Weekly Sales for certain CFG and selected Region
    temp_data <- filter(CFG_fcast.joined,CFG==CFGgroups[i_CFG],Region==Region.groups[i_Region])
    
    if (nrow(temp_data)>0) {
      if (0){
        p_week<- temp_data %>%
          ggplot(aes(x=Fiscal_Wk,y=HDD_QTY,group = Model, color = Model)) +
          geom_point(size = 2) +
          geom_line(size = 1.5,alpha=0.6) +
          labs(title = paste(CFGgroups[i_CFG],Region.groups[i_Region],'HDD Weekly Sales'), x = "Fiscal Week", y = "Part Quantity") + 
          theme_minimal(base_size = 14) + 
          scale_color_tableau('tableau10medium') + 
          scale_x_discrete(breaks = c('FY17W01', 'FY18W01', 'FY19W01')) +
          scale_y_continuous(label=comma) + expand_limits(y = 0)
        l_ggplotly[[(i_CFG-1)*len_Region+i_Region]] <- ggplotly(p_week,width = 999)
        #ggsave(filename = paste(CFGgroups[i],' HDD Weekly Sales',".png",sep = ''), p_week, width=10)
      }
    }
  }
}
l_ggplotly
```

```{r Calculate errors}
# Data transformation for error calculations
CFG_fcast.joined[!is.na(CFG_fcast.joined$Model),] %>% spread(Model,HDD_QTY) %>% ungroup() -> CFG_fcast

CFG_fcast$Ensemble <- rowMeans(select(CFG_fcast,ARIMA,Prophet,TBATS,timetk_RF,timetk_Xgboost), na.rm = TRUE) # removed timetk_lm

CFG_fcast %>% gather(Model,HDD_QTY,ARIMA:Ensemble) -> CFG_fcast.joined.2
write_feather(CFG_fcast.joined.2, "~/Yao_Rdata/CFG_fcast.feather")

read_feather("~/Yao_Rdata/CFG_fcast.feather")

# CFG_fcast.na.omitted <- na.omit(CFG_fcast) %>% # Excluded some CFGs that do not have all model results. I do not want this.
CFG_fcast <- filter(CFG_fcast,Fiscal_Wk>="FY19W07" & Fiscal_Wk<="FY19W20") %>%
  # calculate absolute percent error for MRP
  mutate(ape_MRP = abs((HDD_QTY - MRP_Fcast)/HDD_QTY * 100)) %>%
  # calculate absolute percent error for Prophet
  mutate(ape_Prophet = abs((HDD_QTY - Prophet)/HDD_QTY * 100)) %>%
  # calculate absolute percent error for ARIMA
  mutate(ape_ARIMA = abs((HDD_QTY - ARIMA)/HDD_QTY * 100)) %>%
  # calculate absolute percent error for TBATS
  mutate(ape_TBATS = abs((HDD_QTY - TBATS)/HDD_QTY * 100)) %>%
  # calculate absolute percent error for lm
  mutate(ape_lm = abs((HDD_QTY - timetk_lm)/HDD_QTY * 100)) %>%
  # calculate absolute percent error for RF
  mutate(ape_RF = abs((HDD_QTY - timetk_RF)/HDD_QTY * 100)) %>%
  # calculate absolute percent error for Xgboost
  mutate(ape_Xgboost = abs((HDD_QTY - timetk_Xgboost)/HDD_QTY * 100)) %>%
  # calculate absolute percent error for Ensemble
  mutate(ape_Ensemble = abs((HDD_QTY - Ensemble)/HDD_QTY * 100))

# Get all CFG names, all Region names, and all Model names
CFGgroups2 <- levels(factor(CFG_fcast$CFG))
len_CFG <- length(CFGgroups2)
Region.groups <- levels(factor(CFG_fcast$Region))
len_Region <- length(Region.groups)

results <- foreach(i_CFG=1:len_CFG, .combine=rbind, .packages=c('tidyverse')) %dopar% {
  # HDD Weekly Sales for certain CFG and selected Region
  # For each Region
  OneCFG <- list()
  for (i_Region in 1:len_Region){
    temp_data <- filter(CFG_fcast,CFG==CFGgroups2[i_CFG],Region==Region.groups[i_Region])
    print(paste(CFGgroups2[i_CFG],Region.groups[i_Region],'PASSED!'))
    
    # MRP
    # Weekly Error Calculation
    mape_wk_MRP<- mean(temp_data$ape_MRP,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_MRP <- abs(sum(temp_data$MRP_Fcast)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    # Prophet
    # Weekly Error Calculation
    mape_wk_Prophet<- mean(temp_data$ape_Prophet,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_Prophet <- abs(sum(temp_data$Prophet)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    # ARIMA
    # Weekly Error Calculation
    mape_wk_ARIMA<- mean(temp_data$ape_ARIMA,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_ARIMA <- abs(sum(temp_data$ARIMA)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    # TBATS
    # Weekly Error Calculation
    mape_wk_TBATS<- mean(temp_data$ape_TBATS,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_TBATS <- abs(sum(temp_data$TBATS)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    # timetk lm
    # Weekly Error Calculation
    mape_wk_lm<- mean(temp_data$ape_lm,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_lm <- abs(sum(temp_data$timetk_lm)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    # timetk RF
    # Weekly Error Calculation
    mape_wk_RF<- mean(temp_data$ape_RF,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_RF <- abs(sum(temp_data$timetk_RF)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    # timetk Xgboost
    # Weekly Error Calculation
    mape_wk_Xgboost<- mean(temp_data$ape_Xgboost,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_Xgboost <- abs(sum(temp_data$timetk_Xgboost)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    # Ensemble
    # Weekly Error Calculation
    mape_wk_Ensemble<- mean(temp_data$ape_Ensemble,na.rm = TRUE)
    # 12-week Error Calculation
    APE_fcastPeriod_Ensemble <- abs(sum(temp_data$Ensemble)-sum(temp_data$HDD_QTY))/sum(temp_data$HDD_QTY) * 100
    
    OneRow <- c(CFGgroups2[i_CFG],Region.groups[i_Region],mape_wk_MRP,APE_fcastPeriod_MRP,mape_wk_Prophet,APE_fcastPeriod_Prophet,mape_wk_ARIMA,APE_fcastPeriod_ARIMA,mape_wk_TBATS,APE_fcastPeriod_TBATS,mape_wk_lm,APE_fcastPeriod_lm,mape_wk_RF,APE_fcastPeriod_RF,mape_wk_Xgboost,APE_fcastPeriod_Xgboost,mape_wk_Ensemble,APE_fcastPeriod_Ensemble)
    mape_wk <- as.numeric(OneRow[seq(3,18,2)])
    APE_fcastPeriod <- as.numeric(OneRow[seq(4,18,2)])
    OneRow <- c(OneRow,min(mape_wk),min(APE_fcastPeriod))
    OneCFG <- rbind(OneCFG,OneRow)
  }
  return(OneCFG)
}


dimnames(results)[[2]] <- c('CFG','Region','MAPE_wk_MRP','APE_FcastRegion_MRP','MAPE_wk_Prophet','APE_FcastRegion_Prophet','MAPE_wk_ARIMA','APE_FcastRegion_ARIMA','MAPE_wk_TBATS','APE_FcastRegion_TBATS','MAPE_wk_lm','APE_FcastRegion_lm','MAPE_wk_RF','APE_FcastRegion_RF','MAPE_wk_Xgboost','APE_FcastRegion_Xgboost','MAPE_wk_Ensemble','APE_FcastRegion_Ensemble','MAPE_wk_Selected','APE_FcastRegion_Selected')
results <- data.frame(results)
indx <- c('MAPE_wk_MRP','APE_FcastRegion_MRP','MAPE_wk_Prophet','APE_FcastRegion_Prophet','MAPE_wk_ARIMA','APE_FcastRegion_ARIMA','MAPE_wk_TBATS','APE_FcastRegion_TBATS','MAPE_wk_lm','APE_FcastRegion_lm','MAPE_wk_RF','APE_FcastRegion_RF','MAPE_wk_Xgboost','APE_FcastRegion_Xgboost','MAPE_wk_Ensemble','APE_FcastRegion_Ensemble','MAPE_wk_Selected','APE_FcastRegion_Selected')
results[indx] <- lapply(results[indx], function(x) as.numeric(as.character(x)))
results[c("CFG","Region" )] <- lapply(results[c("CFG","Region" )], function(x) as.character(x))

results %>% left_join(CFG_RGN_QTR_data.grouped, by = c("CFG","Region"="RGN_DESC")) -> results.weight

path <- "~/Yao_Rdata/APE_values.feather"
write_feather(results, path)

# Attainment Rates
Attainment_Rate_Cal <- function(x) {
  length(which(x<=20))/sum(!is.na(x))*100
}

results.clean <- results.weight # consider all CFGs

Eval.results <- list()
# For different Regions
for (i_Region in 1:len_Region){
  data.selected <- filter(results.clean,Region==Region.groups[i_Region])
  AttainmentRates <- lapply(data.selected[indx],Attainment_Rate_Cal)
  # MAPE
  MAPE <- lapply(data.selected[indx],mean, na.rm = TRUE)
  MAPE_median <- lapply(data.selected[indx],median, na.rm = TRUE)
  # Weighted MAPE
  weighted_MAPE <- lapply(data.selected[indx],function(x) sum(x*data.selected$w,na.rm = TRUE))
  # combine
  Eval.results <- rbind(Eval.results,AttainmentRates,MAPE,MAPE_median,weighted_MAPE)
}

Eval.results_fcastRegion <- data.frame(Eval.results[,seq(2,18,2)])
dimnames(Eval.results_fcastRegion)[[2]] <- c('MRP','Prophet','ARIMA','TBATS','lm','RF','Xgboost','Ensemble','Selected')
Eval.results_fcastRegion <- data.frame(Eval.results_fcastRegion,Region=rep(Region.groups,each = 4),Results=c('Attainment_Rates','MAPE','MAPE_median','Weighted_MAPE'))
Eval.results_fcastRegion[,1:9] <- lapply(Eval.results_fcastRegion[,1:9], function(x) as.numeric(as.character(x)))

Eval.results_wk <- data.frame(Eval.results[,seq(1,18,2)])
dimnames(Eval.results_wk)[[2]] <- c('MRP','Prophet','ARIMA','TBATS','lm','RF','Xgboost','Ensemble','Selected')
Eval.results_wk <- data.frame(Eval.results_wk,Region=rep(Region.groups,each = 4),Results=c('Attainment_Rates','MAPE','MAPE_median','Weighted_MAPE'))
Eval.results_wk[,1:9] <- lapply(Eval.results_wk[,1:9], function(x) as.numeric(as.character(x)))

write_feather(Eval.results_fcastRegion,"~/Yao_Rdata/Eval.results_fcastRegion.feather")
write_feather(Eval.results_wk,"~/Yao_Rdata/Eval.results_wk.feather")
```

```{r APE Table}
APE.selected <- results[,c(1,2,seq(4,20,2))]
colnames(APE.selected) <- c("CFG","Region",'MRP','Prophet','ARIMA','TBATS','lm','RF','Xgboost','Ensemble','Selected')

APE.selected %>% datatable(options=list(rowCallback = JS(
  'function(row, data) {
        var num_data = data.slice(1,data.length)
        num_data.sort(function (a, b) {  return a - b;  });
        for(i=1;i < data.length; i++) {
          if(data[i]==num_data[8]) {
          $("td:eq("+i+")", row).css("background-color", "#ffffff")
  } else if(data[i]==num_data[7]) {
        $("td:eq("+i+")", row).css("background-color", "#e6ffe6")
  } else if(data[i]==num_data[6]) {
        $("td:eq("+i+")", row).css("background-color", "#b3ffb3")
  } else if(data[i]==num_data[5]) {
        $("td:eq("+i+")", row).css("background-color", "#80ff80")
  } else if(data[i]==num_data[4]) {
        $("td:eq("+i+")", row).css("background-color", "#4dff4d")
  } else if(data[i]==num_data[3]) {
        $("td:eq("+i+")", row).css("background-color", "#1aff1a")
  } else if(data[i]==num_data[2]) {
        $("td:eq("+i+")", row).css("background-color", "#00e600")
  }
        }
  }'))) %>% 
  formatRound(columns=c('MRP','Prophet','ARIMA','TBATS','lm','RF','Xgboost','Ensemble','Selected'), digits=2) 
```


```{r Visualize Errors}
ggplotly(filter(Eval.results_fcastRegion,Region==Region.groups[1],Results=='Weighted_MAPE') %>% 
           select(-Region,-Results,-Selected) %>%
           gather(key="Model",value="Value") %>%
           ggplot(aes(Model,Value)) +
           geom_bar(stat = "identity") +
           labs(title = paste('Model Comparison by Forecast Region Accuracy'), x = "Models", y = paste(str_replace_all('Weighted_MAPE','_',' '),"(%)")) + 
           theme_minimal(base_size = 14) + 
           scale_fill_tableau('tableau10medium'))

ggplotly(filter(Eval.results_wk,Region==Region.groups[1],Results=='Weighted_MAPE') %>% 
           select(-Region,-Results,-Selected) %>%
           gather(key="Model",value="Value") %>%
           ggplot(aes(Model,Value)) +
           geom_bar(stat = "identity") +
           labs(title = paste('Model Comparison by Weekly Accuracy'), x = "Models", y = paste(str_replace_all('Weighted_MAPE','_',' '),"(%)")) + 
           theme_minimal(base_size = 14) + 
           scale_fill_tableau('tableau10medium'))

```

```{r close the cluster}
# for Parallel package
stopImplicitCluster()
```

```{r Best Selection for the test region}
APE.selected <- results[,c(1,2,seq(4,20,2))]
colnames(APE.selected) <- c("CFG","Region",'MRP','Prophet','ARIMA','TBATS','lm','RF','Xgboost','Ensemble','Selected')
APE.selected$Selection <- apply(APE.selected,1,function(x) names(which.min(x[4:10])))
APE.selected[c("Selection" )] <- lapply(APE.selected[c("Selection" )], function(x) as.factor(as.character(x)))
write_feather(APE.selected,"~/Yao_Rdata/TestSelection.feather")
APE.selected <- read_feather("~/Yao_Rdata/TestSelection.feather")
```

