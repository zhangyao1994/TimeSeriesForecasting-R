---
title: "HDD Data Exploratory Analytics from SQL Server"
author: "Yao"
date: "May 23-31,06/04, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(plotly)
library(scales)
library(ggthemes)
library(ggrepel)
options(scipen = 999)
```

## Load Database from SQL Server

```{r ConnectDB}
library(DBI)
db = dbConnect(odbc::odbc(),
               driver = 'SQL Server',
               server = 'IRISAGL01.aus.amer.dell.com',
               user = 'Yao_Z',
               password = 'y67uhgt@Y')
```

It is not well known that you can run SQL code in an R Notebook code chunk. To use SQL, open an R Notebook in the RStudio IDE under the File > New File menu. Start a new code chunk with {sql}, and specify your connection with the connection=con code chunk option. If you want to send the query output to an R dataframe use output.var = "mydataframe" in the code chunk options. When you specify output.var you will be able to use the output in subsequent R code chunks. In this example, we use the output in ggplot.

```{sql connection=db, output.var="Weekly_HDD_QTY_OnlyDetails"}
SELECT Order_Date_week, SUM(ITM_QTY) AS HDD_QTY
FROM IRIS.[Base].[ISG_Business_Transformation.isgOrdersDetails]
WHERE ITM_TYPE LIKE '%HDD%' OR ITM_TYPE LIKE 'HARD%DRIVE%' AND DELL_EMC_ORDER_FLAG = 'DELL' AND (LOB_DESC IN ('PowerEdge','Cloud Products') OR MGMT_PROD_LVL_3_NM = 'Storage')
GROUP BY Order_Date_week
ORDER BY Order_Date_week
```


```{r plot}
Weekly_HDD_QTY_OnlyDetails %>% na.omit %>%
  ggplot(aes(x=Order_Date_week,y=HDD_QTY,group=1)) + 
  geom_point(size = 2) +
  geom_line(size = 1.5) +
  labs(title = 'HDD Weekly Sales 201701-201915', x = "Fiscal Week", y = "Part Quantity") + 
  theme_minimal(base_size = 18) + 
  scale_color_tableau('tableau10medium') + 
  scale_x_discrete(breaks = c('201701','201801', '201901')) +
  theme(legend.position = 'none',plot.title = element_text(hjust = 0.5))+
  scale_y_continuous(label=comma) + expand_limits(y = 0)
```

```{r HDD Attach Rate}
# 5/29/2018
# Load the extracted data from SQL server
HDD_data <- read.csv("~/HDD_ATT_RATE.csv")

# Make a histogram plot
HDD_data %>%
  ggplot(aes(ATT_RATE)) + 
  geom_histogram() +
  labs(title = 'HDD Attach Rate 201701-201915', x = "Attach Rate", y = "Count") + 
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5)) 

# As we can see, the attach rate of HDD vary a lot, so it is important to forecast the part quantity of HDD.
```

```{sql hdd_qty, connection=db, output.var = 'hdd_qty'}
SELECT 
  D.Cfg_Desc AS CFG, C.Fiscal_Qtr, C.Fiscal_Mo, C.Fiscal_Wk, C.Fiscal_Wk_End_Date, C.Fiscal_Date, C.Fiscal_Yr, B.Order_Date_week, C.Fiscal_Mo_End_Date, C.Fiscal_Qtr_End_Date,
  CASE WHEN A.LOB_DESC = 'PowerEdge' AND A.ESI_order_flag = 'Y' THEN 'PowerEdge - ESI'
                     WHEN A.MGMT_PROD_LVL_3_NM = 'Storage' AND A.DELL_EMC_ORDER_FLAG = 'DELL' THEN 'Storage - DELL'
                ELSE A.LOB_DESC END AS LOB_DESC, A.BRAND_CATG_DESC, 
  A.RGN_DESC,
  A.GBL_PARNT_ACCT_NM AS Customer, 
  SUM(SYS_QTY_DELL) AS SYS_QTY,
  SUM(ITM_QTY) AS PART_QTY
FROM IRIS.[Base].[ISG_Business_Transformation.isgOrders] AS A 
JOIN IRIS.[Base].[ISG_Business_Transformation.isgOrdersDetails] B
ON A.ORD_NBR = B.ORD_NBR AND A.FMLY_PFOLIO_DESC = B.FMLY_PFOLIO_DESC AND A.SRC_BU_ID = B.SRC_BU_ID
JOIN IRIS.DIM.Date C
ON B.ORD_DT = C.Fiscal_Date
JOIN IRIS_Data_Mart.[dbo].[SKU_CFG_Bridge] D
ON B.ITM_NBR = D.sku_num
WHERE D.Cfg_Desc LIKE '%HDD%' AND Commodity_Desc IN ('Hard Drive', 'Controller Cards/HBA') AND C.Fiscal_Yr >= 'FY16' AND A.DELL_EMC_ORDER_FLAG = 'DELL' AND (A.LOB_DESC IN ('PowerEdge','Cloud Products') OR A.MGMT_PROD_LVL_3_NM = 'Storage')
GROUP BY
  D.Cfg_Desc, C.Fiscal_Qtr, C.Fiscal_Mo, C.Fiscal_Wk, C.Fiscal_Wk_End_Date, C.Fiscal_Date, C.Fiscal_Yr, B.Order_Date_week, C.Fiscal_Mo_End_Date, C.Fiscal_Qtr_End_Date,
  CASE WHEN A.LOB_DESC = 'PowerEdge' AND A.ESI_order_flag = 'Y' THEN 'PowerEdge - ESI'
                   WHEN A.MGMT_PROD_LVL_3_NM = 'Storage' AND A.DELL_EMC_ORDER_FLAG = 'DELL' THEN 'Storage - DELL'
                   ELSE A.LOB_DESC END, A.BRAND_CATG_DESC, 
  A.RGN_DESC, A.GBL_PARNT_ACCT_NM
ORDER BY D.Cfg_Desc, C.Fiscal_Qtr, C.Fiscal_Mo, C.Fiscal_Wk
```



```{r Deal with missing data}
Weekly_HDD_QTY_combined <- hdd_qty %>% group_by(Order_Date_week) %>% summarise(Fiscal_Wk_QTY=sum(PART_QTY))

apply(hdd_qty, 2, function(x) any(is.na(x)))

# Columns have NA: Customer
hdd_qty = hdd_qty %>% 
  mutate(Customer = ifelse(
    grepl('Dummy|disti|\032|APPOINTED|ACCT-R', Customer, ignore.case = T) | Customer == '' | is.na(Customer),
    'Unknown_Customer', Customer
  ))

apply(hdd_qty, 2, function(x) any(is.na(x)))
# All NAs have been cleaned.

rm(db)
rm(Weekly_HDD_QTY_combined)

save.image("~/HDD_QTY_IRIS.RData")
```


