---
title: "IRIS HDD Forecasting for each CFG by Region with Cross-Validation"
author: "Yao"
date: "June 27, 2018"
output: html_document
---

This is the parallel function version using weekly data and different models, including TBATS, Prophet, ARIMA, lm, and Random Forest, to forecast one quarter HDD demand with one quarter ahead and with cross-validation.
Update on 6/27/2018.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
options(scipen = 999)
library(lubridate)

# Load egboost relevant libraries
library(quantmod); library(TTR); library(xgboost);

# Load timetk package
library(tidyquant)
library(timetk)
library(broom)

# Random Forest
library(party)
library(randomForest)

# Load TBATS package, as well as for ARIMA
library(forecast)

# Load Facebook Prophet package
library(Rcpp)
library(prophet)

library(scales) # for percent

# make the code parallel using 'parallel' package
library(iterators)
library(parallel)
library(foreach)
library(doParallel)

library(feather)
 
# Calculate the number of cores
no_cores <- detectCores() - 1
registerDoParallel(no_cores)
```

## IRIS HDD Weekly Demand Forecasting for each CFG

```{r load the data}
load("~/Yao_Rdata/HDD_QTY_IRIS.RData")

# Weekly data
hdd_qty %>% group_by(CFG, RGN_DESC, Fiscal_Wk_End_Date,Fiscal_Wk,Fiscal_Qtr) %>%
  summarise(HDD_QTY = sum(PART_QTY)) -> HDD_Weekly
```

```{r Forecast Function}
myforecast <- function(){
  df <- data.frame(ds = temp_data$date, y = temp_data$HDD_QTY)
  n <- nrow(df)
  
  MultiQtr_Fcast <- list()
  for (i_Qtr in 1:4){
    # Split into training and test sets
    # i=1: At the beginning of FY18Q1, forecast FY18Q1 and FY18Q2 and only calculate the accuracy of FY18Q2
    Fcast_TimePoint <- filter(temp_data,Fiscal_Qtr==Fcast_Qtr[i_Qtr])$date[1]
    Fcast_EndPoint <- filter(temp_data,Fiscal_Qtr==Fcast_Qtr[i_Qtr+2])$date[1]
    train <- df %>% filter(ds < Fcast_TimePoint)
    test <- df %>% filter(ds >= Fcast_TimePoint & ds < Fcast_EndPoint)
    
    WeekAhead <- length(filter(temp_data,Fiscal_Qtr==Fcast_Qtr[i_Qtr])$date)
    forecastPeriodLen <- length(filter(temp_data,Fiscal_Qtr==Fcast_Qtr[i_Qtr+1])$date) + WeekAhead
    
    if (nrow(test) !=26 | nrow(train)<2){
      OneQtrFcast <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],rep(NA,26+1))
      MultiQtr_Fcast <- rbind(MultiQtr_Fcast,OneQtrFcast)
      next
    }
    
    Truth <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'Truth',test$y)
    
    # Add time series signature # For the last date of train region
    train_augmented <- train[nrow(train),] %>%
      tk_augment_timeseries_signature()
    
    HDD.ts <- ts(train$y,frequency=365.25/7, end = train_augmented$year+train_augmented$yday/365.25)
    
    # TBATS
    fit <- tbats(HDD.ts)
    fcast <- forecast(fit,h=forecastPeriodLen)
    TBATS_fcast <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'TBATS',fcast$mean)
    
    # ARIMA
    if (i_CFG %in% c(16,17,40,55,87) & i_Region==3){
      ARIMA_fcast <- (c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'ARIMA',rep(NA,forecastPeriodLen)))
    } else {
      fit <- auto.arima(HDD.ts) # Some might fail # ,D=1
      fcast <- forecast(fit,h=forecastPeriodLen)
      ARIMA_fcast <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'ARIMA',fcast$mean)
    }
    
    # Prophet
    m <- prophet(train)
    future <- make_future_dataframe(m, periods = forecastPeriodLen, freq = 'week',include_history = FALSE)
    fcast <- predict(m, future)
    Prophet_fcast <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'Prophet',fcast$yhat)
    
    # lm
    # Add time series signature
    train_augmented <- train %>%
      tk_augment_timeseries_signature()
    # maunually drop unvalid variables
    temp <-
      train_augmented %>% select(-wday.lbl,-month.lbl,-diff)
    # Remove the column with only one value
    if (nrow(temp)>1) {
      temp <- Filter(function(x)(length(unique(x))>1), temp)
    }
    
    # Model using the augmented features
    fit <- lm(y ~ ., data = na.omit(temp)) # Will need to try using less number of features! Avoid overfitting.
    # We need to again augment the time series signature to the test set.
    test_augmented <- test %>%
      tk_augment_timeseries_signature()
    yhat_test <- predict(fit, newdata = test_augmented)
    lm_fcast <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'timetk_lm',yhat_test)
    
    # Random Forest
    # Model using the augmented features
    fit <- randomForest(y ~ ., data = na.omit(temp))
    yhat_test <- predict(fit, newdata = test_augmented)
    RF_fcast <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'timetk_RF',yhat_test)
    
    # Xgboost
    # Train the xgboost model using the "xgboost" function
    dtrain = xgb.DMatrix(data = as.matrix(select(temp,-y,-ds)), label = temp$y)
    xgModel = xgboost(data = dtrain, nrounds = ceiling(sqrt(nrow(dtrain)))) # sqrt(nrow(dtrain)), I guess
    # Make the predictions on the test data
    temp_test <- test_augmented[,colnames(temp)]
    preds = predict(xgModel, as.matrix(select(temp_test,-y,-ds)))
    Xgboost_fcast <- c(CFGgroups[i_CFG],Regions[i_Region],Fcast_Qtr[i_Qtr],'timetk_Xgboost',preds)
    
    OneQtrFcast <- rbind(Truth,TBATS_fcast,ARIMA_fcast,Prophet_fcast,lm_fcast,RF_fcast,Xgboost_fcast)
    MultiQtr_Fcast <- rbind(MultiQtr_Fcast,OneQtrFcast)
  }
  return(MultiQtr_Fcast)
}
```


```{r Run the fuctions parallel}
HDD_Weekly$date <- ymd(HDD_Weekly$Fiscal_Wk_End_Date)
CFGgroups <- levels(factor(HDD_Weekly$CFG))
len <- length(CFGgroups)

Regions <- levels(factor(HDD_Weekly$RGN_DESC))
num.Regions <- length(Regions)
Fcast_Qtr <- c("FY18Q1","FY18Q2","FY18Q3","FY18Q4","FY19Q1","FY19Q2")

Comb_fcast <- data.frame()
for (i_Region in 1:num.Regions){
  Comb_fcast0 <- foreach(i_CFG=1:len, .combine=rbind, .packages=c('tidyverse','forecast','Rcpp','ggthemes','lubridate','tidyquant','timetk','prophet','randomForest','party','quantmod','TTR','xgboost')) %dopar% {
    # Forecast for each CFG
    temp_data <- HDD_Weekly %>% filter(CFG==CFGgroups[i_CFG],RGN_DESC==Regions[i_Region])
    oneCFG_fcast <- myforecast()
    oneCFG_fcast
  }
  Comb_fcast <- rbind(Comb_fcast,Comb_fcast0)
}

# Assign Colume names
weekNames <- c(sprintf("W0%d", 1:9),sprintf("W%d", 10:26))
dimnames(Comb_fcast)[[2]] <- c('CFG','Region','Quarter','Model',as.character(weekNames))
# HDD quntatity should be numeric.
Comb_fcast[,5:ncol(Comb_fcast)] <- lapply(Comb_fcast[,5:ncol(Comb_fcast)], function(x) as.numeric(as.character(x)))
Comb_fcast[,1:4] <- lapply(Comb_fcast[,1:4], function(x) as.character(x))
# Transformation
Comb_fcast %>% gather(key='Fiscal_Wk',value='HDD_QTY',W01:W26) -> All_fcast

# For plot, do not delete the NA for now.
# saveRDS(All_fcast, 'All_fcast_CV.rds') # my_data <- readRDS(file)
write_feather(All_fcast,"~/Yao_Rdata/All_fcast_cv.feather")
```

```{r close the clusters}
# for Parallel package
stopImplicitCluster()
```
