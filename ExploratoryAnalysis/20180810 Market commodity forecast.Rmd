---
title: "HDD SSD Memory forecast"
author: "Cinkie You"
date: "July 25, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(DBI)

db_iris = dbConnect(odbc::odbc(),
                    driver = 'SQL Server',
                    server = 'IRISAGL01.aus.amer.dell.com',
                    user = 'SSRS_User',
                    password = 'SSRS_User')

```


```{sql get_part_data, connection=db_iris, output.var = 'data_td_isg'}

SELECT D.Commodity_Desc, D.CFG, B.Fiscal_Qtr, B.Calendar_Qtr, B.Fiscal_Mo, B.Fiscal_Wk, B.Fiscal_Wk_End_Date, SUM(PART_ITM_QTY) AS ITM_QTY
FROM [IRIS].[Base].[SLS_PKG.ACTL_SALE_PART_SMRY_VW] A
JOIN IRIS.DIM.date_hyperion_v AS B
ON A.PART_SLS_DT = B.Fiscal_Date
JOIN IRIS.[Base].[ITM_PKG.COMB_PROD_HIER] C
ON A.INT_COMB_PROD_HIER_CD = C.COMB_HIER_CD
JOIN (
SELECT Commodity_Desc, Cfg_Desc AS CFG, DPN
FROM IRIS.Base.[PRCMT_BASE.CFG_PART] A
JOIN IRIS.Base.[PRCMT_BASE.CFG_MSTR] B
ON A.CFG_ID = B.CFG_ID
JOIN IRIS.DIM.DPN C
ON A.PART_NBR = C.DPN
GROUP BY Commodity_Desc, DPN, Cfg_Desc
) D
ON A.PART_ITM_NBR = D.DPN
WHERE C.TYPE_DESC = 'Enterprise Solution Group PBU' AND C.PROD_GRP_DESC IN ('PowerEdge Servers','Cloud Servers', 'Storage') AND D.Commodity_Desc IN ('Hard Drive', 'Memory')
GROUP BY D.Commodity_Desc, D.CFG, B.Fiscal_Qtr, B.Calendar_Qtr, B.Fiscal_Mo, B.Fiscal_Wk, B.Fiscal_Wk_End_Date
ORDER BY D.Commodity_Desc, D.CFG, B.Fiscal_Wk

```



```{sql get_dell_calendar, connection=db_iris, output.var = 'dell_calendar'}

SELECT Fiscal_Wk, Fiscal_Wk_End_Date, Fiscal_Mo, Calendar_Qtr, Fiscal_Qtr, Fiscal_Yr
FROM IRIS.DIM.date_hyperion_v
GROUP BY Fiscal_Wk, Fiscal_Wk_End_Date, Fiscal_Mo, Calendar_Qtr, Fiscal_Qtr, Fiscal_Yr

```


```{r clean_data}


cfg_attr_group = read.csv('~/Yao_Excels/HDD SSD Memory CFG Attributes.csv')
cfg_attr_group$sku_desc = NULL

## Weekly data
data_part_cfg = data_td_isg %>% 
  left_join(cfg_attr_group, by = 'CFG') %>% 
  filter(ITM_TYPE %in% c('HDD', 'SSD', 'MEMORY')) %>% 
  select(-Commodity_Desc) %>% 
  ## exclude month without complete data
  filter(Fiscal_Mo > "FY17M06") %>% 
  as.data.frame()

pre_proc_add_life_cycle = function(data_part_cfg, cadence = c("Month", "Week"), dell_calendar, cfg_attr_group){
  
  if (cadence == "Week"){
    
    full_wk_list = sort(unique(data_part_cfg$Fiscal_Wk_End_Date))
    
    cfg_start_wk = data_part_cfg %>% 
      group_by(CFG) %>% 
      filter(ITM_QTY > 0) %>% 
      filter(Fiscal_Wk_End_Date == min(Fiscal_Wk_End_Date)) %>% 
      select(CFG, Fiscal_Wk_End_Date) %>% 
      rename(Start_Wk = Fiscal_Wk_End_Date)
    
    cfg_end_wk = data_part_cfg %>% 
      group_by(CFG) %>% 
      filter(ITM_QTY > 0) %>% 
      filter(Fiscal_Wk_End_Date == max(Fiscal_Wk_End_Date)) %>% 
      select(CFG, Fiscal_Wk_End_Date) %>% 
      rename(End_Wk = Fiscal_Wk_End_Date)
    
    data_part_cfg_wk = data_part_cfg %>% 
      group_by(CFG) %>% 
      ## expand to complete week list
      expand(Fiscal_Wk_End_Date = full_wk_list) %>% 
      left_join(dell_calendar, by = "Fiscal_Wk_End_Date") %>% 
      left_join(data_part_cfg, by = c("CFG", "Fiscal_Wk_End_Date", "Fiscal_Wk", "Fiscal_Mo", "Calendar_Qtr", "Fiscal_Qtr")) %>% 
      mutate(ITM_QTY = coalesce(ITM_QTY, 0)) %>% 
      ## get CFG start and end week
      left_join(cfg_start_wk %>% left_join(cfg_end_wk, by = "CFG"), by = 'CFG') %>% 
      ## exclude weeks beyond lifecycle
      filter(Fiscal_Wk_End_Date >= Start_Wk & Fiscal_Wk_End_Date <= End_Wk) %>% 
      mutate(life_cycle_length_current = n_distinct(Fiscal_Wk_End_Date)) %>% 
      group_by(CFG) %>% 
      mutate(CFG_TTL_ITM_QTY = sum(ITM_QTY)) %>% 
      mutate(ESI_Flag = ifelse(grepl('ESI|DCS|DSS|NSO', CFG), 'Y','N')) %>% 
      as.data.frame()
    
    return(data_part_cfg_wk)
    
  }else if (cadence == "Month"){
    
    full_mo_list = sort(unique(data_part_cfg$Fiscal_Mo))
    
    cfg_start_mo = data_part_cfg %>% 
      group_by(CFG) %>% 
      filter(ITM_QTY > 0) %>% 
      filter(Fiscal_Mo == min(Fiscal_Mo)) %>% 
      distinct(CFG, Fiscal_Mo) %>% 
      rename(Start_Mo = Fiscal_Mo)
    
    cfg_end_mo = data_part_cfg %>% 
      group_by(CFG) %>% 
      filter(ITM_QTY > 0) %>% 
      filter(Fiscal_Mo == max(Fiscal_Mo)) %>% 
      distinct(CFG, Fiscal_Mo) %>% 
      rename(End_Mo = Fiscal_Mo)
    
    data_part_cfg_mo = data_part_cfg %>% 
      group_by(CFG) %>% 
      ## expand to complete week list
      expand(Fiscal_Mo = full_mo_list) %>% 
      left_join(dell_calendar %>% distinct(Fiscal_Mo, Fiscal_Qtr, Calendar_Qtr), by = "Fiscal_Mo") %>% 
      left_join(data_part_cfg %>% 
                  group_by(CFG, Fiscal_Mo) %>% 
                  summarise(ITM_QTY = sum(ITM_QTY)), 
                by = c("CFG", "Fiscal_Mo")) %>% 
      mutate(ITM_QTY = coalesce(ITM_QTY, 0)) %>% 
      ## get CFG start and end month
      left_join(cfg_start_mo %>% left_join(cfg_end_mo, by = "CFG"), by = 'CFG') %>% 
      ## exclude weeks beyond lifecycle
      filter(Fiscal_Mo >= Start_Mo & Fiscal_Mo <= End_Mo) %>% 
      mutate(life_cycle_length_current = n_distinct(Fiscal_Mo)) %>% 
      group_by(CFG) %>% 
      mutate(CFG_TTL_ITM_QTY = sum(ITM_QTY)) %>% 
      mutate(ESI_Flag = ifelse(grepl('ESI|DCS|DSS|NSO', CFG), 'Y','N')) %>% 
      left_join(cfg_attr_group, by = "CFG") %>% 
      as.data.frame()
    
    return(data_part_cfg_mo)
    
  }
}

data_part_cfg_wk = pre_proc_add_life_cycle(data_part_cfg, "Week", dell_calendar, cfg_attr_group)
data_part_cfg_mo = pre_proc_add_life_cycle(data_part_cfg, "Month", dell_calendar, cfg_attr_group)

```

```{r cfg_analytics}

head(data_part_cfg)

############# Content Analysis #############
data_part_cfg %>% 
  group_by(ITM_TYPE, Fiscal_Mo) %>% 
  summarise(Capacity_Qty = sum(ITM_QTY * Capacity_Num, na.rm = T)) %>% 
  filter(Fiscal_Mo < 'FY19M06') %>%
  ggplot(aes(x = Fiscal_Mo, y = Capacity_Qty)) +
  facet_wrap(~ITM_TYPE, nrow = 1, scales = "free_y") +
  geom_line(aes(group = 1), size = 2, alpha = 0.6, color = tableau_color_pal("Tableau 10")(2)[1]) +
  geom_point(aes(group = 1), size = 2, color = tableau_color_pal("Tableau 10")(2)[1]) +
  scale_color_tableau() +
  scale_y_continuous(labels = scales::unit_format(unit = "PB", scale = 1e-6)) +
  scale_x_discrete(breaks = c('FY17M01','FY18M01','FY19M01')) +
  theme_bw() +
  labs(x = "", y = "Capacity", 
       title = "ISG Commodity Monthly Total Capacity FY17 - FY19M05")

data_part_cfg %>% 
  group_by(ITM_TYPE, Fiscal_Mo) %>% 
  summarise(Total_Qty = sum(ITM_QTY)) %>% 
  filter(Fiscal_Mo < 'FY19M06') %>%
  ggplot(aes(x = Fiscal_Mo, y = Total_Qty)) +
  facet_wrap(~ITM_TYPE, nrow = 1, scales = "free_y") +
  geom_line(aes(group = 1), size = 2, alpha = 0.6, color =tableau_color_pal("Tableau 10")(2)[2]) +
  geom_point(aes(group = 1), size = 2, color = tableau_color_pal("Tableau 10")(2)[2]) +
  scale_color_tableau() +
  scale_y_continuous(labels = scales::unit_format(unit = "k", scale = 1e-3)) +
  scale_x_discrete(breaks = c('FY17M07','FY18M01', 'FY18M07','FY19M01')) +
  theme_bw() +
  labs(x = "", y = "Part Quantity", 
       title = "ISG Commodity Monthly Part Quantity FY17M06 - FY19M06")

data_part_cfg %>% 
  filter(ITM_TYPE != 'MEMORY') %>% 
  mutate(Capacity_Group = case_when(
    Capacity_Num < 500 ~ '< 500G',
    Capacity_Num >= 500 & Capacity_Num < 1000 ~ '500G - 1T',
    Capacity_Num >= 1000 & Capacity_Num < 2000 ~ '1T - 2T',
    Capacity_Num >= 2000 & Capacity_Num < 4000 ~ '2T - 4T',
    Capacity_Num >= 4000 ~ '> 4T',
    is.na(Capacity_Num) ~ 'NA',
    T ~ 'Others'
  )) %>% 
  mutate(Capacity_Group = ordered(Capacity_Group, levels = c('< 500G', '500G - 1T', '1T - 2T', '2T - 4T', '> 4T', 'NA'))) %>% 
  group_by(ITM_TYPE, Calendar_Qtr, Capacity_Group) %>% 
  summarise(Total_Qty = sum(ITM_QTY)) %>% 
  filter(Calendar_Qtr < 'CY18CQ2') %>%
  ggplot(aes(x = Calendar_Qtr, y = Total_Qty, fill = Capacity_Group)) +
  facet_wrap(~ITM_TYPE, nrow = 1, scales = "free_y") +
  geom_area(aes(group = Capacity_Group), position = 'stack', stat = 'identity') +
  scale_fill_tableau() +
  scale_y_continuous(labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  scale_x_discrete(breaks = c('CY16CQ1','CY17CQ1','CY18CQ1')) +
  theme_bw() +
  labs(x = "", y = "Part Quantity", 
       title = "ISG Commodity Quarterly Part Quantity CY16 - CY18CQ1")

data_part_cfg %>% 
  filter(ITM_TYPE == 'MEMORY') %>%
  group_by(Capacity) %>% 
  summarise(y = sum(ITM_QTY)) %>% 
  mutate(ptg = y/sum(y))

data_part_cfg %>% 
  filter(ITM_TYPE == 'MEMORY') %>% 
  mutate(Capacity_Group = case_when(
    Capacity_Num < 4 ~ '< 4G',
    Capacity_Num == 4 ~ '4G',
    Capacity_Num == 8 ~ '8G',
    Capacity_Num == 16 ~ '16G',
    Capacity_Num == 32 ~ '32G',
    Capacity_Num == 64 ~ '64G',
    is.na(Capacity_Num) ~ 'NA',
    T ~ 'Others'
  )) %>% 
  mutate(Capacity_Group = ordered(Capacity_Group, levels = c('< 4G', '4G', '8G', '16G', '32G', '64G', 'NA', 'Others'))) %>% 
  group_by(ITM_TYPE, Calendar_Qtr, Capacity_Group) %>% 
  summarise(Total_Qty = sum(ITM_QTY)) %>% 
  filter(Calendar_Qtr < 'CY18CQ2') %>%
  ggplot(aes(x = Calendar_Qtr, y = Total_Qty, fill = Capacity_Group)) +
  facet_wrap(~ITM_TYPE, nrow = 1, scales = "free_y") +
  geom_area(aes(group = Capacity_Group), position = 'stack', stat = 'identity') +
  scale_fill_tableau() +
  scale_y_continuous(labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  scale_x_discrete(breaks = c('CY16CQ1','CY17CQ1','CY18CQ1')) +
  theme_bw() +
  labs(x = "", y = "Part Quantity", title = "")




############# Interface / Memory Generation Analysis #############

data_part_cfg %>% 
  filter(ITM_TYPE != 'MEMORY') %>% 
  #mutate(Interface_w_Speed = ifelse(is.na(Interface_w_Speed), 'NA', as.factor(Interface_w_Speed))) %>% 
  group_by(ITM_TYPE, Calendar_Qtr, Interface_w_Speed) %>% 
  summarise(Total_Qty = sum(ITM_QTY)) %>% 
  filter(Calendar_Qtr < 'CY18CQ2') %>%
  ggplot(aes(x = Calendar_Qtr, y = Total_Qty, fill = Interface_w_Speed)) +
  facet_wrap(~ITM_TYPE, nrow = 1, scales = "free_y") +
  geom_area(aes(group = Interface_w_Speed), position = 'stack', stat = 'identity') +
  scale_fill_tableau("Tableau 20") +
  scale_y_continuous(labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  scale_x_discrete(breaks = c('CY16CQ1','CY17CQ1','CY18CQ1')) +
  theme_bw() +
  labs(x = "", y = "Part Quantity", 
       title = "ISG Commodity Quarterly Part Quantity CY16Q3 - CY18CQ1", subtitle = 'By interface, HDD & SSD')


data_part_cfg %>% 
  filter(ITM_TYPE == 'MEMORY') %>% 
  # mutate(Memory_DIMM_Type = ifelse(is.na(Memory_DIMM_Type), 'NA', Memory_DIMM_Type)) %>% 
  group_by(ITM_TYPE, Calendar_Qtr, Memory_DIMM_Type) %>% 
  summarise(Total_Qty = sum(ITM_QTY)) %>% 
  filter(Calendar_Qtr < 'CY18CQ2') %>%
  ggplot(aes(x = Calendar_Qtr, y = Total_Qty, fill = Memory_DIMM_Type)) +
  facet_wrap(~ITM_TYPE, nrow = 1, scales = "free_y") +
  geom_area(aes(group = Memory_DIMM_Type), position = 'stack', stat = 'identity') +
  scale_fill_tableau("Tableau 20") +
  scale_y_continuous(labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  scale_x_discrete(breaks = c('CY16CQ1','CY17CQ1','CY18CQ1')) +
  theme_bw() +
  labs(x = "", y = "Part Quantity", 
       title = "", subtitle = 'By DIMM type, Memory')

data_part_cfg %>% 
  group_by(ITM_TYPE, CFG_GROUP) %>% 
  summarise(Total_Qty = sum(ITM_QTY)) %>% 
  group_by(ITM_TYPE) %>% 
  top_n(3, Total_Qty) %>% 
  left_join(
    data_part_cfg %>% 
      group_by(ITM_TYPE, CFG_GROUP, Fiscal_Wk) %>% 
      summarize(ITM_QTY = sum(ITM_QTY)) %>% 
      filter(Fiscal_Wk < max(Fiscal_Wk)), by = c("ITM_TYPE", "CFG_GROUP")) %>% 
  ggplot(aes(x = Fiscal_Wk, y = ITM_QTY, color = CFG_GROUP)) +
  facet_wrap(~ITM_TYPE, ncol = 1, scales = 'free_y') +
  geom_line(aes(group = CFG_GROUP), size = 2, alpha = 0.8) +
  theme_pander() +
  scale_color_tableau() +
  scale_x_discrete(breaks = c("FY17W01","FY18W01","FY19W01")) +
  labs(title = 'Top 3 CFG Group Weekly Demand', x = 'Fiscal Week', y = 'Part Quantity')


```


```{r forecast_functions}

calculate_attain = function(y, yhat){
  
  ## attain = actual / forecast
  attain = numeric(length = length(y))
  
  for (i in seq_along(y)){
    if (yhat[i] != 0){
      attain[i] = y[i]/yhat[i]
    }else if (y[i] == 0 & yhat[i] == 0){
      attain[i] = 1
    }else if ( y[i] != 0 & yhat[i] == 0){
      attain[i] = 0
    }
  }
  return(attain)
}

calculate_attain_flag = function(attain){
  
  attain_flag = character(length = length(attain))
  
  for (i in seq_along(attain)){
    
    if (attain[i] >= 0.8 & attain[i] <= 1.2){
      attain_flag[i] = "Green"
    }else if (attain[i] > 1.2){
      attain_flag[i] = "Red"
    }else if (attain[i] < 0.8){
      attain_flag[i] = "Blue"
    }else{
      attain_flag[i] = NA
    }
  }
  
  return(attain_flag)
}

calculate_ape = function(y, yhat){
  
  ape = numeric(length = length(y))
  
  for (i in seq_along(y)){
    
    if (y[i] == 0 & yhat[i] == 0){
      ape[i] = 0
    }else if (y[i] == 0 & yhat[i] != 0){
      # assgin a large number instead of inifnite
      ape[i] = 10
    }else{
      ape[i] = abs(y[i] - yhat[i])/y[i]
    }
  }
  
  return(ape)
}


mean_one = function(data_part_train, data_part_test, one_item, data_cadence, n_wk = 13){
  
  data_part_train_one = data_part_train %>% filter(CFG_New == one_item)
  data_part_test_one = data_part_test %>% filter(CFG_New == one_item)
  
  if (data_cadence == "Weekly"){
    
    latest_n_wkly_mean = data_part_train_one %>% 
      top_n(n_wk, ds) %>% 
      summarise(wk_mean = mean(y))
    
  }else if (data_cadence == "Daily"){
    
    latest_n_wkly_mean = data_part_train_one %>% 
      top_n(n_wk * 7, ds) %>% 
      summarise(wk_mean = sum(y) / n_wk)
    
  }
  
  result_tmp = data_part_test_one %>% 
    group_by(CFG_New) %>% 
    summarise(y = sum(y), yhat = latest_n_wkly_mean$wk_mean * 13) %>% 
    mutate(attain = calculate_attain(y, yhat),
           attain_flag = calculate_attain_flag(attain),
           ape = calculate_ape(y,yhat)) %>% 
    ungroup()
  
  return(result_tmp)
}

arima_one =function(data_part_train, data_part_test, one_item){
  
  data_part_train_one = data_part_train %>% filter(CFG_New == one_item)
  data_part_test_one = data_part_test %>% filter(CFG_New == one_item)
  
  train_ts = with(data_part_train_one %>% select(-CFG_New), zoo(y, order.by = ds))
  
  m_arima = auto.arima(train_ts)
  
  m_fcst = forecast(m_arima, h = 26)
  
  
  result_tmp = data_part_test_one %>% 
    group_by(CFG_New) %>% 
    summarise(y = sum(y), yhat = sum(m_fcst$mean[14:26])) %>% 
    mutate(attain = calculate_attain(y, yhat),
           attain_flag = calculate_attain_flag(attain),
           ape = calculate_ape(y,yhat)) %>%  
    ungroup()
  
  return(result_tmp)
}

ets_one =function(data_part_train, data_part_test, one_item){
  
  data_part_train_one = data_part_train %>% filter(CFG_New == one_item) %>% ungroup()
  data_part_test_one = data_part_test %>% filter(CFG_New == one_item) %>% ungroup()
  
  train_ts = with(data_part_train_one %>% select(-CFG_New), zoo(y, order.by = ds))
  
  m_ets = ets(train_ts)
  
  m_fcst = forecast(m_ets, h = 26)
  
  result_tmp = data_part_test_one %>% 
    group_by(CFG_New) %>% 
    summarise(y = sum(y), yhat = sum(m_fcst$mean[14:26])) %>% 
    mutate(attain = calculate_attain(y, yhat),
           attain_flag = calculate_attain_flag(attain),
           ape = calculate_ape(y,yhat)) %>% 
    ungroup()
  
  return(result_tmp)
}

bass_one =function(data_part_train, data_part_test, one_item){
  
  data_part_train_one = data_part_train %>% filter(CFG_New == one_item) %>% ungroup()
  data_part_test_one = data_part_test %>% filter(CFG_New == one_item) %>% ungroup()
  
  train_ts = as.ts(data_part_train_one$y)
  
  tryCatch({
    m_bass = diffusion(train_ts, cumulative = F)
    
    m_fcst = predict(m_bass, h = 26)
    
  }, error = function(e){print(paste("No Bass curve for", one_item))})
  
  if (exists("m_fcst")){
    result_tmp = data_part_test_one %>% 
      group_by(CFG_New) %>% 
      summarise(y = sum(y), yhat = sum(m_fcst$frc[14:26, "Adoption"])) %>% 
      mutate(attain = calculate_attain(y, yhat),
             attain_flag = calculate_attain_flag(attain),
             ape = calculate_ape(y,yhat)) %>% 
      ungroup()
  }else{
    result_tmp = data_part_test_one %>% 
      group_by(CFG_New) %>% 
      summarise(y = sum(y), yhat = NA, attain = NA, attain_flag = NA, ape = NA) %>% 
      ungroup()
  }
  
  return(result_tmp)
}

prophet_one = function(data_part_train, data_part_test, one_item){
  
  data_part_train_one = data_part_train %>% filter(CFG_New == one_item)
  data_part_test_one = data_part_test %>% filter(CFG_New == one_item)
  
  tryCatch({
    ## train and forecast
    prophet.fit = prophet(data_part_train_one)
    
    future = data.frame(ds = data_part_test_one$ds)
    forecast = predict(prophet.fit, future)
  }, error = function(e){print(paste("No prophet for", one_item))})
  
  if (exists("forecast")){
    result_tmp = data_part_test_one %>% 
      left_join(forecast %>% 
                  mutate(ds = as.character(ds)), by = "ds") %>% 
      group_by(CFG_New) %>% 
      summarise(y = sum(y), yhat = sum(yhat)) %>% 
      mutate(attain = calculate_attain(y, yhat),
             attain_flag = calculate_attain_flag(attain),
             ape = calculate_ape(y,yhat)) %>% 
      ungroup()
  }else{
    result_tmp = data_part_test_one %>% 
      group_by(CFG_New) %>% 
      summarise(y = sum(y), yhat = NA, attain = NA, attain_flag = NA, ape = NA) %>% 
      ungroup()
  }
  return(result_tmp)
}

xgboost_one = function(data_part_train, data_part_test, one_item){
  
  data_part_train_one = data_part_train %>% filter(CFG_New == one_item)
  data_part_test_one = data_part_test %>% filter(CFG_New == one_item)
  
  data_part_train_one = data_part_train_one %>% 
    select(-CFG_New) %>% 
    mutate(ds = as.Date(ds))
  
  timetk_train_data = data_part_train_one %>% 
    tk_augment_timeseries_signature() %>% 
    select(-c(ds, diff, month.lbl, wday.lbl))
  
  m1 = xgboost(data = as.matrix(select(timetk_train_data, -y)), label = timetk_train_data$y, nrounds = 20, verbose = 0)
  
  timetk_test_data = as.Date(data_part_test_one$ds) %>% 
    tk_get_timeseries_signature() %>% 
    select(-c(index, diff, month.lbl, wday.lbl))
  
  timetk_forecast = predict(m1, newdata = as.matrix(timetk_test_data))
  
  result_tmp = data_part_test_one %>% 
    group_by(CFG_New) %>% 
    summarise(y = sum(y), yhat = sum(timetk_forecast)) %>% 
    mutate(attain = calculate_attain(y, yhat),
           attain_flag = calculate_attain_flag(attain),
           ape = calculate_ape(y,yhat)) %>% 
    ungroup()
  
  return(result_tmp)
}


## forecst function , ahead is the month
forecast_cfg = function(data_part, test_qtrs, ahead = 3, data_cadence = c("Daily","Weekly"), cfg_ptg_threshold = 1, cfg_col = "CFG"){
  
  qtr_mo_tbl = data_part %>% 
    distinct(Calendar_Qtr, Fiscal_Mo) %>% 
    arrange(Fiscal_Mo)
  
  cmdy_list = sort(unique(data_part$ITM_TYPE))
  
  part_result = tibble(
    ITM_TYPE = character(0), CFG_New = character(0), test_qtr = character(0), model = character(0),
    y = numeric(0), yhat = numeric(0),
    attain = numeric(0), attain_flag = character(0), ape = numeric(0), num_cfg = numeric(0)
  )
  
  data_part = data_part %>% 
    rename_("CFG_New" = cfg_col)
  
  for (test_qtr in test_qtrs){
    
    # train end time (smaller than this train_end_qtr)
    train_end_mo = qtr_mo_tbl$Fiscal_Mo[min(which(qtr_mo_tbl$Calendar_Qtr == test_qtr)) - ahead]
    
    for (cmdy in cmdy_list){
      
      if (data_cadence == "Weekly"){
        
        data_part_tmp = data_part %>% 
          filter(ITM_TYPE == cmdy) %>% 
          group_by(Calendar_Qtr, Fiscal_Mo, Fiscal_Wk_End_Date, CFG_New) %>% 
          summarise(y = sum(ITM_QTY)) %>% 
          ungroup()
        
        data_part_tmp_train = data_part_tmp %>% 
          filter(Fiscal_Mo < train_end_mo) %>% 
          select(CFG_New, Fiscal_Wk_End_Date, y)
        
        data_part_tmp_test = data_part_tmp %>% 
          filter(Calendar_Qtr == test_qtr) %>% 
          select(CFG_New, Fiscal_Wk_End_Date, y)
        
        ## forecast the CFGs that exists in botn train and test set
        cfg_list_tmp = setdiff(intersect(unique(data_part_tmp_test$CFG_New), unique(data_part_tmp_train$CFG_New)), NA)
        
        ## not forecast CFGs with small volume, exclude CFGs based on their quantity contribution to cmdy total
        cfg_list_tbl_sm_vol = data_part_tmp_train %>% 
          group_by(CFG_New) %>% 
          summarise(y = sum(y)) %>% 
          arrange(desc(y)) %>% 
          mutate(cum_ptg = cumsum(y)/sum(y)) %>% 
          filter(cum_ptg > cfg_ptg_threshold)
        
        ## filter CFGs that have less than 3 historical data points
        cfg_list_tbl_no_data = data_part_tmp_train %>% 
          group_by(CFG_New) %>%
          summarise(n_wk = n_distinct(Fiscal_Wk_End_Date)) %>% 
          mutate(rm_flag = n_wk <= 3) %>% 
          # filter(y > 0) %>% 
          # filter(Fiscal_Wk_End_Date == min(Fiscal_Wk_End_Date)) %>% 
          # mutate(ds = ymd(Fiscal_Wk_End_Date),
          #        rm_flag = (ds + weeks(3) >= max(data_part_tmp_train$Fiscal_Wk_End_Date))) %>% 
          filter(rm_flag)
        
        cfg_list_rm = unique(union(cfg_list_tbl_sm_vol$CFG_New, cfg_list_tbl_no_data$CFG_New))
        
        cfg_list_test = setdiff(cfg_list_tmp, cfg_list_rm)
        
        ## CFGs removed in test
        data_test_rm_vol = data_part_tmp_test %>%
          mutate(cfg_rm_flag = !(CFG_New %in% cfg_list_test)) %>% 
          group_by(cfg_rm_flag) %>% 
          summarise(rm_y = sum(y)) %>% 
          mutate(rm_ptg = rm_y / sum(rm_y)) %>% 
          filter(cfg_rm_flag)
        
        data_part_train = data_part_tmp_train %>% 
          filter(CFG_New %in% cfg_list_test) %>% 
          rename(ds = Fiscal_Wk_End_Date) %>% 
          arrange(CFG_New, ds)
        
        data_part_test = data_part_tmp_test %>% 
          filter(CFG_New %in% cfg_list_test) %>% 
          rename(ds = Fiscal_Wk_End_Date) %>% 
          arrange(CFG_New, ds)
        
      }else if (data_cadence == "Daily"){
        
        data_part_tmp = data_part %>% 
          filter(ITM_TYPE == cmdy) %>% 
          group_by(Calendar_Qtr, Fiscal_Mo, Fiscal_Wk, Fiscal_Date, CFG_New) %>% 
          summarise(y = sum(ITM_QTY)) %>% 
          ungroup()
        
        data_part_tmp_train = data_part_tmp %>% 
          filter(Fiscal_Mo < train_end_mo) %>% 
          select(CFG_New, Fiscal_Date, y)
        
        data_part_tmp_test = data_part_tmp %>% 
          filter(Calendar_Qtr == test_qtr) %>% 
          select(CFG_New, Fiscal_Date, y)
        
        ## forecast the CFGs that exists in botn train and test set
        cfg_list_tmp = setdiff(intersect(unique(data_part_tmp_test$CFG_New), unique(data_part_tmp_train$CFG_New)), NA)
        
        ## not forecast CFGs with small volume, exclude CFGs based on their quantity contribution to cmdy total
        cfg_list_tbl_sm_vol = data_part_tmp_train %>% 
          group_by(CFG_New) %>% 
          summarise(y = sum(y)) %>% 
          arrange(desc(y)) %>% 
          mutate(cum_ptg = cumsum(y)/sum(y)) %>% 
          filter(cum_ptg > cfg_ptg_threshold)
        
        ## filter CFGs that have less than 3 week historical data points
        cfg_list_tbl_no_data = data_part_tmp_train %>% 
          group_by(CFG_New) %>% 
          filter(y > 0) %>% 
          filter(Fiscal_Date == min(Fiscal_Date)) %>% 
          mutate(ds = ymd(Fiscal_Date),
                 rm_flag = (ds + weeks(3) >= max(data_part_tmp_train$Fiscal_Date))) %>% 
          filter(rm_flag)
        
        cfg_list_rm = unique(union(cfg_list_tbl_sm_vol$CFG_New, cfg_list_tbl_no_data$CFG_New))
        
        cfg_list_test = setdiff(cfg_list_tmp, cfg_list_rm)
        
        ## CFGs removed in test
        data_test_rm_vol = data_part_tmp_test %>%
          mutate(cfg_rm_flag = !(CFG_New %in% cfg_list_test)) %>% 
          group_by(cfg_rm_flag) %>% 
          summarise(rm_y = sum(y)) %>% 
          mutate(rm_ptg = rm_y / sum(rm_y)) %>% 
          filter(cfg_rm_flag)
        
        data_part_train = data_part_tmp_train %>% 
          filter(CFG_New %in% cfg_list_test) %>% 
          rename(ds = Fiscal_Date) %>% 
          arrange(CFG_New, ds)
        
        data_part_test = data_part_tmp_test %>% 
          filter(CFG_New %in% cfg_list_test) %>% 
          rename(ds = Fiscal_Date) %>% 
          arrange(CFG_New, ds)
      }
      # ---------------------------------------- Mean ---------------------------------------- #####
      
      result_mean = foreach(i = 1:length(cfg_list_test), .combine = rbind, 
                            .packages = c("dplyr"), 
                            .export = c("mean_one", "calculate_attain", "calculate_attain_flag", "calculate_ape")) %dopar% {
                              
                              mean_one(data_part_train, data_part_test, cfg_list_test[i], data_cadence, n_wk = 13)  } 
      result_mean$model = "Naive Mean"
      
      # ---------------------------------------- Arima ---------------------------------------- #####
      
      result_arima = foreach(i = 1:length(cfg_list_test), .combine = rbind, 
                             .packages = c("dplyr", "zoo", "forecast"), 
                             .export = c("arima_one", "calculate_attain", "calculate_attain_flag", "calculate_ape")) %dopar% {
                               
                               arima_one(data_part_train, data_part_test, cfg_list_test[i])  } 
      result_arima$model = "ARIMA"
      
      # ---------------------------------------- ETS ---------------------------------------- #####
      
      result_ets = foreach(i = 1:length(cfg_list_test), .combine = rbind, 
                           .packages = c("dplyr", "zoo", "forecast"), 
                           .export = c("ets_one", "calculate_attain", "calculate_attain_flag", "calculate_ape")) %dopar% {
                             
                             ets_one(data_part_train, data_part_test, cfg_list_test[i])  } 
      result_ets$model = "ETS"
      
      # ---------------------------------------- BASS Diffusion ---------------------------------------- #####
      
      result_bass = foreach(i = 1:length(cfg_list_test), .combine = rbind, 
                            .packages = c("dplyr", "diffusion", "zoo", "forecast"), 
                            .export = c("bass_one", "calculate_attain", "calculate_attain_flag", "calculate_ape")) %dopar% {
                              
                              bass_one(data_part_train, data_part_test, cfg_list_test[i])  } 
      result_bass$model = "Bass"
      
      # ---------------------------------------- XGBoost ---------------------------------------- #####
      result_xgboost = foreach(i = 1:length(cfg_list_test), .combine = rbind, 
                               .packages = c("dplyr", "xgboost", "timetk"), 
                               .export = c("xgboost_one", "calculate_attain", "calculate_attain_flag", "calculate_ape")) %dopar% {
                                 
                                 xgboost_one(data_part_train, data_part_test, cfg_list_test[i])  } 
      
      result_xgboost$model = "XGBoost"
      
      # ---------------------------------------- Prophet ---------------------------------------- #####
      result_prophet = foreach(i = 1:length(cfg_list_test), .combine = rbind,
                               .packages = c("prophet","dplyr"),
                               .export = c("prophet_one", "calculate_attain", "calculate_attain_flag","calculate_ape")) %dopar% {
                                 
                                 prophet_one(data_part_train, data_part_test, cfg_list_test[i])  }
      
      result_prophet$model = "Prophet"
      
      # ---------------------------------------- Aggregate results ---------------------------------------- #####
      result_tmp = bind_rows(result_mean, result_arima, result_ets, result_prophet, result_bass, result_xgboost)
      
      result_tmp$num_cfg = length(cfg_list_test)
      
      result_tmp = result_tmp %>% 
        mutate(ITM_TYPE = cmdy, test_qtr = test_qtr)
      
      if (nrow(data_test_rm_vol) == 0){
        
        result_tmp = result_tmp %>% 
          mutate(rm_y = 0, rm_y_ptg = 0)
        
      }else{
        
        result_tmp = result_tmp %>% 
          mutate(rm_y = data_test_rm_vol$rm_y,
                 rm_y_ptg = data_test_rm_vol$rm_ptg)
      }
      
      part_result = bind_rows(part_result, result_tmp)
      
      rm(result_tmp, data_part_tmp, data_part_tmp_train, data_part_tmp_test, data_test_rm_vol)
    }## end of ITM_TYPE loop
    
  }## end of test quarters loop
  
  return(part_result)
}


```

```{r forecast}

library(doParallel)


data_part_cfg_wk_in_scope = data_part_cfg_wk %>% 
  filter(grepl('ESG|MEM', CFG) & ESI_Flag == 'N')

write_feather(data_part_cfg_wk_in_scope,'~/Yao_Rdata/data_part_cfg_wk_in_scope.feather')

## initiate parallel computing
cores = detectCores()
parallel_clusters = makeCluster(cores[1]-1)
registerDoParallel(parallel_clusters)

#############  First run forecast for commodity CFGs  #############
## Test on 4 quarters
test_qtrs = c("CY17CQ3", "CY17CQ4", "CY18CQ1", "CY18CQ2")

## forecast months ahead
# part_cfg_result_2 = forecast_cfg(data_part_cfg_wk_in_scope, test_qtrs, ahead = 2, data_cadence = "Weekly", cfg_col = "CFG")
part_cfg_result_3 = forecast_cfg(data_part_cfg_wk_in_scope, test_qtrs, ahead = 3, data_cadence = "Weekly", cfg_col = "CFG")
# part_cfg_result_4 = forecast_cfg(data_part_cfg_wk_in_scope, test_qtrs, ahead = 4, data_cadence = "Weekly", cfg_col = "CFG")

stopCluster(parallel_clusters)


```

```{r forecast_result_analysis}

result_summary = part_cfg_result_2 %>%
  filter(!is.na(attain)) %>%
  group_by(ITM_TYPE, model, test_qtr) %>%
  summarise(wmape = sum(y * ape/sum(y), na.rm = T)) %>%
  group_by(ITM_TYPE, model) %>%
  summarise(mape = mean(wmape, na.rm = T)) %>%
  mutate(ahead = "2 Month") %>%
  bind_rows(
    part_cfg_result_3 %>%
      filter(!is.na(attain)) %>%
      group_by(ITM_TYPE, model, test_qtr) %>%
      summarise(wmape = sum(y * ape/sum(y), na.rm = T)) %>%
      group_by(ITM_TYPE, model) %>%
      summarise(mape = mean(wmape, na.rm = T)) %>%
      mutate(ahead = "3 Month")) %>%
  bind_rows(
    part_cfg_result_4 %>%
      group_by(ITM_TYPE, model, test_qtr) %>%
      summarise(wmape = sum(y * ape/sum(y), na.rm = T)) %>%
      group_by(ITM_TYPE, model) %>%
      summarise(mape = mean(wmape, na.rm = T)) %>%
      mutate(ahead = "4 Month"))

result_summary %>%
  ggplot(aes(x = model, y = mape, fill = ahead)) +
  facet_wrap(~ITM_TYPE) +
  geom_bar(stat = 'identity', position = 'dodge') +
  geom_text(aes(label = paste0(round(100*mape), '%')), colour = 'white', fontface = 'bold',
            size = 3.5, position = position_dodge(width = 0.8), vjust = 1) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_economist() +
  theme_bw() +
  labs(x = '', y = "Weighted MAPE",
       title = "ISG Commodity Quarterly CFG Weighted MAPE",fill = "Ahead")

part_cfg_result_3 %>% 
  filter(!is.na(attain)) %>% 
  group_by(ITM_TYPE, model, test_qtr) %>% 
  summarise(wmape = sum(y * ape/sum(y), na.rm = T)) %>% 
  group_by(ITM_TYPE, model) %>% 
  summarise(mape = mean(wmape, na.rm = T)) %>% 
  mutate(ahead = "3 Month") %>%
  select(-ahead) %>% 
  spread(key = model, value = mape) %>% 
  write_csv('tmp.csv')


part_cfg_result_3 %>%
  filter(!is.na(attain)) %>%
  mutate(ape = calculate_ape(y, yhat)) %>%
  group_by(ITM_TYPE, model, test_qtr) %>%
  summarise(wmape = sum(y * ape/sum(y), na.rm = T)) %>% 
  spread(key = model, value = wmape) %>% 
  write_csv('tmp.csv')

## relationship between volume and accuracy
part_cfg_result_3 %>%
  filter(!is.na(attain) & model %in% c("Naive Mean", "XGBoost") & test_qtr == 'CY18CQ2') %>%
  ggplot(aes(x = y, y = ape)) +
  facet_wrap(model~ITM_TYPE, scales = 'free') +
  geom_point() +
  scale_y_continuous(labels = scales::percent, limits = c(0,5)) +
  scale_x_continuous(labels = scales::comma) +
  theme_classic() +
  labs(x = "CFG Total Volume", y = "Absolute Percentage Error",
       title = "Scatterplot of CFG volume vs error rate", subtitle = "Test quarter CY18CQ2; Forecast 1 quarter ahead",
       caption = "Error rate > 200% excluded from chart")


# ggplot(aes(x = test_qtr, y = wmape, fill = model)) +
# facet_wrap(~ITM_TYPE, nrow = 1) +
# geom_bar(stat = 'identity', position = 'dodge') +
# scale_y_continuous(labels = scales::percent) +
# scale_fill_tableau() +
# theme_bw() +
# theme(axis.text.x = element_text(size = 8)) +
# labs(y = 'Weighted MAPE', x = 'Test Quarter', title = 'Weighted MAPE by test quarters',
#      subtitle = "Forecast one quarter ahead")

# ## percentage of cmdy volume for CFG removed from forecast
# part_cfg_result_3 %>% 
#   distinct(ITM_TYPE, test_qtr, rm_y_ptg) %>% 
#   arrange(ITM_TYPE) %>% 
#   ggplot(aes(x = ITM_TYPE, y = rm_y_ptg, fill = test_qtr)) +
#   geom_bar(stat = 'identity', position = 'dodge', alpha = 0.8) +
#   geom_text(aes(label = paste0(round(100*rm_y_ptg), '%')), colour = 'white', fontface = 'bold',
#             size = 4, position = position_dodge(width = 0.85), vjust = 1) +
#   scale_y_continuous(labels = scales::percent) +
#   scale_fill_gdocs() +
#   theme_bw() +
#   labs(x = '', y = "% Part Quantity", 
#        title = "% Part Quantity Removed from Forecasting - Forecast 1 Quarter Ahead",fill = "Test Quarter")

```


```{r compare_lock_result}

lock_guidance = read.csv("~/Yao_Excels/Lock Guidance CY18CQ2 Results(1).csv")

lock_q2_result = lock_guidance %>% 
  select(-Actual,-ITM_TYPE,-Interface) %>%
  filter(Calendar_Qtr == 'CY18CQ2' & Lock_Forecast > 0) %>% 
  left_join(data_part_cfg_wk %>% 
              filter(Calendar_Qtr == 'CY18CQ2') %>% 
              group_by(CFG, Calendar_Qtr) %>% 
              summarise(Actual = sum(ITM_QTY)), by = c("CFG", "Calendar_Qtr")) %>% 
  mutate(Actual = coalesce(Actual, 0)) %>% 
  mutate(Lock_APE = calculate_ape(Actual, Lock_Forecast),
         Lock_Attain_Rate = calculate_attain(Actual, Lock_Forecast),
         Lock_Attain_Flag = calculate_attain_flag(Lock_Attain_Rate)) %>% 
  left_join(cfg_attr_group, by = c("CFG")) %>% 
  arrange(ITM_TYPE, Interface)

## compare models result with LOCK in terms of MAPE
lock_q2_result %>% 
  select(CFG, Actual, Lock_APE) %>% 
  rename(Lock = Lock_APE) %>% 
  left_join(
    part_cfg_result_3 %>% 
      filter(test_qtr == 'CY18CQ2') %>% 
      select(ITM_TYPE, CFG_New, model, ape) %>% 
      spread(key = ITM_TYPE + CFG_New, value = ape), by = c('CFG' = 'CFG_New')
  ) %>%
  gather(key = "model", value = "ape", Lock,ARIMA,Prophet,Bass,ETS,`Naive Mean`,XGBoost) %>%
  group_by(ITM_TYPE, model) %>% 
  summarise(wmape = sum(Actual * ape/sum(Actual), na.rm = T)) %>% 
  spread(key = model, value = wmape) %>% 
  filter(!is.na(ITM_TYPE)) %>%
  write_csv('tmp.csv')

## compare models result with LOCK in terms of attainment 
lock_q2_result %>% 
  select(CFG, Actual, Lock_Attain_Flag) %>% 
  rename(Lock = Lock_Attain_Flag) %>% 
  left_join(
    part_cfg_result_3 %>% 
      filter(test_qtr == 'CY18CQ2') %>% 
      select(ITM_TYPE, CFG_New, model, attain_flag) %>% 
      spread(key = ITM_TYPE + CFG_New, value = attain_flag), by = c('CFG' = 'CFG_New')
  ) %>% 
  gather(key = "model", value = "Flag", Lock,ARIMA,Prophet,Bass,ETS,`Naive Mean`,XGBoost) %>%
  group_by(ITM_TYPE, model, Flag) %>% 
  summarise(n_cfg = n_distinct(CFG)) %>% 
  group_by(ITM_TYPE, model) %>% 
  mutate(n_cfg_ptg = n_cfg/sum(n_cfg)) %>% 
  filter(!is.na(ITM_TYPE)) %>% 
  ungroup() %>% 
  mutate(Flag = coalesce(Flag, "NA")) %>% 
  mutate(Flag = ordered(Flag, levels = c("Red", "Green", "Blue", "NA"))) %>% 
  mutate(model = ifelse(model == "Naive Mean", "Mean", model)) %>% 
  mutate(model = ordered(model, levels = c("ARIMA", "Prophet", "Bass", "ETS", "Mean", "XGBoost", "Lock"))) %>%
  ggplot(aes(x = model, y = n_cfg_ptg, fill = Flag)) +
  facet_wrap(~ITM_TYPE, nrow = 1) +
  geom_bar(stat = 'identity') +
  geom_text(aes(label = paste0(round(100*n_cfg_ptg), '%')), colour = 'white', fontface = 'bold',
            size = 4, position = position_stack(), vjust = 1) +
  scale_fill_manual(values = c("#E15759", "#59A14F","#4E79A7", "grey")) +
  scale_y_continuous(labels = scales::percent) +
  theme_hc() +
  theme(axis.text.x = element_text(size = 8)) +
  labs(x = '', y = '% CFG Quantity', title = "Model Attainment and 'Accuracy'", subtitle = "CY18CQ2; Forecast 1 quarter ahead")


## compare models result with LOCK in terms of weighted attainment
lock_q2_result %>% 
  select(CFG, Actual, Lock_Attain_Flag) %>% 
  rename(Lock = Lock_Attain_Flag) %>% 
  left_join(
    part_cfg_result_3 %>% 
      filter(test_qtr == 'CY18CQ2') %>% 
      select(ITM_TYPE, CFG_New, model, attain_flag) %>% 
      spread(key = ITM_TYPE + CFG_New, value = attain_flag), by = c('CFG' = 'CFG_New')
  ) %>% 
  gather(key = "model", value = "Flag", Lock,ARIMA,Prophet,Bass,ETS,`Naive Mean`,XGBoost) %>%
  group_by(ITM_TYPE, model, Flag) %>% 
  summarise(y = sum(Actual)) %>% 
  group_by(ITM_TYPE, model) %>% 
  mutate(ptg = y/sum(y)) %>% 
  filter(!is.na(ITM_TYPE)) %>% 
  ungroup() %>% 
  mutate(Flag = coalesce(Flag, "NA")) %>% 
  mutate(Flag = ordered(Flag, levels = c("Red", "Green", "Blue", "NA"))) %>% 
  mutate(model = ifelse(model == "Naive_Mean", "Mean", model)) %>% 
  mutate(model = ordered(model, levels = c("ARIMA","Prophet", "Bass", "ETS", "Mean", "XGBoost", "Lock"))) %>% 
  ggplot(aes(x = model, y = y, fill = Flag)) +
  facet_wrap(~ITM_TYPE, nrow = 1) +
  geom_bar(stat = 'identity') +
  geom_text(aes(label = paste0(round(100*ptg), '%')), colour = 'white', fontface = 'bold',
            size = 4, position = position_stack(), vjust = 1) +
  scale_fill_manual(values = c("#E15759", "#59A14F","#4E79A7", "grey")) +
  scale_y_continuous(labels = scales::comma) +
  theme_hc() +
  theme(axis.text.x = element_text(size = 8)) +
  labs(x = '', y = '% CFG Quantity', title = "Model Attainment and 'Accuracy'", subtitle = "CY18CQ2; Forecast 1 quarter ahead")


```

