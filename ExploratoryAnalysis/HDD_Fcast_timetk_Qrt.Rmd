---
title: "HDD Forecasting timetk Quarterly"
author: "Yao"
date: "6/4/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
options(scipen = 999)

# Load timetk package # 06/04/2018
library(tidyquant)
library(timetk)
library(broom)
```

## HDD Forecasting

According to the webpage example, let me test this model on daily HDD data.
However, the daily demand data does not provide good forecast results.
I uploaded the daily forecasting code to github.
After testing on weekly and monttly data, let me work on quarterly demand here then.

### Data

```{r load the data}
load("HDD_QTY_IRIS.RData")

# Quarterly data
hdd_qty %>% group_by(Fiscal_Qtr_End_Date) %>%
  summarise(HDD_QTY=sum(PART_QTY)) -> HDD_Quarterly
```

```{r Visualization}
# Select date and count
HDD_Quarterly$date <- ymd(HDD_Quarterly$Fiscal_Qtr_End_Date)

HDD_Quarterly <- HDD_Quarterly %>%
  filter(date<'2018-08-03') %>% select(date,HDD_QTY)

# Visualize data and training/testing regions
HDD_Quarterly %>%
    ggplot(aes(x = date, y = HDD_QTY)) +
    geom_point(alpha = 0.5, color = palette_light()[[1]]) +
    geom_line() +
    labs(title = "HDD Quarterly Demand: Quarterly Scale", x = "Fiscal Date",y='Quarterly Demand') +
    theme_tq() +
    annotate("text", x = ymd("2017-03-20"), y = 220000,
             color = palette_light()[[1]], label = "Train Region") +
    annotate("text", x = ymd("2018-03-10"), y = 230000,
             color = palette_light()[[1]], label = "Test Region") +
    geom_rect(xmin = as.numeric(ymd("2018-01-01")),
              xmax = as.numeric(ymd("2018-05-19")),
              ymin = 0, ymax = 2200000,
              fill = palette_light()[[4]], alpha = 0.01) + 
    expand_limits(y = 0)
```

Split the data into train and test sets at "2018-01".

```{r Split tin training and test sets}
# Split into training and test sets
train <- HDD_Quarterly %>%
    filter(date < ymd("2018-01-01"))

test <- HDD_Quarterly %>%
    filter(date >= ymd("2018-01-01"))
```

### Modeling
Start with the training set, which has the "date" and "HDD_QTY" columns.

```{r Adding time series signature}
# Training set
head(train)

# Add time series signature
train_augmented <- train %>%
    tk_augment_timeseries_signature()
head(train_augmented)
```

Now that we have a number of fields that can be used for training, we can use these for modeling. In practice, you will want to go through the process of pre-processing the data, centering and scaling if necessary, making dummy variables, removing correlated variables that are present, examining interactions, etc. For brevity, we do not do this here.

```{r Model using the augmented features}
train_augmented <- train_augmented %>% select(-wday.lbl)
# Model using the augmented features
fit_lm <- lm(HDD_QTY ~ ., data = train_augmented)
```

We can examine the model residuals to see if there is any significant pattern remaining using augment() from the broom package.

```{r Visualize the residuals of training set}
# Visualize the residuals of training set
fit_lm %>%
    augment() %>%
    ggplot(aes(x = date, y = .resid)) +
    geom_hline(yintercept = 0, color = "red") +
    geom_point(color = palette_light()[[1]], alpha = 0.5) + 
    theme_tq() +
    labs(title = "Training Set: lm() Model Residuals", x = "") #+
    #scale_y_continuous(limits = c(-5000, 5000))
```


We can also get a quick idea of the overall error of the model on the training set. Note that what we really care about is the error on the test set, as this is a much better predictor of future model performance.

```{r RMSE}
# RMSE
sqrt(mean(fit_lm$residuals^2))
```


### Test Validation

With a suitable model (low residual error and random residuals) we can forecast using the "test" set for validation purposes.
Anyways, let me validate this Quarterly model.

```{r Validation}
head(test)

# We need to again augment the time series signature to the test set.
test_augmented <- test %>%
    tk_augment_timeseries_signature()
head(test_augmented)

yhat_test <- predict(fit_lm, newdata = test_augmented)

pred_test <- test %>%
    add_column(yhat = yhat_test) %>%
    mutate(.resid = HDD_QTY - yhat)
head(pred_test)
```

```{r Results Visualization}
ggplot(aes(x = date), data = HDD_Quarterly) +
    labs(title = "HDD Quarterly Demand: Quarterly Scale", x = "Fiscal Date",y='Quarterly Demand') +
    theme_tq() +
    annotate("text", x = ymd("2017-03-20"), y = 220000,
             color = palette_light()[[1]], label = "Train Region") +
    annotate("text", x = ymd("2018-03-10"), y = 230000,
             color = palette_light()[[1]], label = "Test Region") +
    geom_rect(xmin = as.numeric(ymd("2018-01-01")),
              xmax = as.numeric(ymd("2018-05-19")),
              ymin = 0, ymax = 2200000,
              fill = palette_light()[[4]], alpha = 0.01) + 
    expand_limits(y = 0) +
    geom_point(aes(x = date, y = HDD_QTY), data = train, alpha = 0.5, color = palette_light()[[1]]) + 
    geom_line(aes(x = date, y = HDD_QTY), data = train, alpha = 0.5, color = palette_light()[[1]]) +
    geom_point(aes(x = date, y = HDD_QTY), data = pred_test, alpha = 0.5, color = palette_light()[[1]]) + 
    geom_line(aes(x = date, y = HDD_QTY), data = pred_test, alpha = 0.5, color = palette_light()[[1]]) +
    geom_point(aes(x = date, y = yhat), data = pred_test, alpha = 0.5, color = palette_light()[[2]]) + 
    geom_line(aes(x = date, y = yhat), data = pred_test, alpha = 0.5, color = palette_light()[[2]]) +
    theme_tq() 
```

### Test Accuracy
The forecast accuracy can be evaluated on the test set using residual diagnostics and forecast accuracy measures.

```{r Calculating forecast error}
# Calculating forecast error
error_tbl <- pred_test %>%
  mutate(pct_err = .resid/HDD_QTY * 100) %>%
  summarize(
    me = mean(.resid, na.rm = TRUE),
    rmse = mean(.resid^2, na.rm = TRUE)^0.5,
    mae = mean(abs(.resid), na.rm = TRUE),
    mape = mean(abs(pct_err), na.rm = TRUE),
    mpe = mean(pct_err, na.rm = TRUE)
  )

error_tbl
```

Next we can visualize the residuals of the test set. The residuals of the model aren't perfect, but we can work with it. The residuals show that the model predicts too low in Jan and APr.

```{r}
ggplot(aes(x = date, y = .resid), data = pred_test) +
    geom_hline(yintercept = 0, color = "red") +
    geom_point(color = palette_light()[[1]], alpha = 0.5) +
    geom_smooth() +
    theme_tq() +
    labs(title = "Test Set: lm() Model Residuals", x = "") #+
    #scale_y_continuous(limits = c(-5000, 5000))
```

### Forecasting

Let's use our model to predict What are the expected future values for the next six months. The first step is to create the date sequence. Let's use tk_get_timeseries_summary() to review the summary of the dates from the original dataset, "HDD_Quarterly".

```{r Review the summary of the dates from the orginal dataset}
# Extract HDD index
idx <- HDD_Quarterly %>%
    tk_index()

# Get time series summary from index
HDD_summary <- idx %>%
    tk_get_timeseries_summary()

HDD_summary[1:6]

HDD_summary[7:12]
```

From the summary, we know that the data is 100% regular because the median and mean differences are 86400 seconds or 1 day. We don't need to do any special inspections when we use tk_make_future_timeseries(). If the data was irregular, meaning weekends or holidays were excluded, you'd want to account for this. Otherwise your forecast would be inaccurate.

```{r Create idx for the future}
idx_future <- idx %>%
    tk_make_future_timeseries(n_future = 2)
```

To make the prediction, we need to use the future index to get the time series signature (tk_get_timeseries_signature()). Make sure to rename the column "index" to "date" so it matches the column names of the original data.

```{r make the prediction}
data_future <- idx_future %>%
    tk_get_timeseries_signature() %>%
    rename(date = index)

pred_future <- predict(fit_lm, newdata = data_future)

HDD_future <- data_future %>%
    select(date) %>%
    add_column(HDD_QTY = pred_future)
```

```{r Forecast Visualization}
HDD_Quarterly %>%
    ggplot(aes(x = date, y = HDD_QTY)) +
    geom_rect(xmin = as.numeric(ymd("2018-01-01")),
              xmax = as.numeric(ymd("2018-05-19")),
              ymin = 0, ymax = 2200000,
              fill = palette_light()[[4]], alpha = 0.01) +
    geom_rect(xmin = as.numeric(ymd("2018-05-20")),
              xmax = as.numeric(ymd("2018-11-20")),
              ymin = 0, ymax = 2200000,
              fill = palette_light()[[3]], alpha = 0.01) +
    annotate("text", x = ymd("2017-03-20"), y = 220000,
             color = palette_light()[[1]], label = "Train Region") +
    annotate("text", x = ymd("2018-03-10"), y = 230000,
             color = palette_light()[[1]], label = "Test Region") +
    expand_limits(y = 0) +
    annotate("text", x = ymd("2018-08-20"), y = 240000,
             color = palette_light()[[1]], label = "Forecast Region") +
    geom_point(alpha = 0.5, color = palette_light()[[1]]) +
    geom_line(alpha = 0.5, color = palette_light()[[1]]) +
    geom_point(aes(x = date, y = HDD_QTY), data = HDD_future,
               alpha = 0.5, color = palette_light()[[2]]) +
    geom_line(aes(x = date, y = HDD_QTY), data = HDD_future) + 
    labs(title = "HDD Quarterly Demand: 6-Month Forecast", x = "Fiscal Date",y='Quarterly Demand') +
    theme_tq()

```

### Forecast Error

A forecast is never perfect. We need prediction intervals to account for the variance from the model predictions to the actual data. There's a number of methods to achieve this. We'll follow the prediction interval methodology from Forecasting: Principles and Practice.

```{r Calculate standard deviation of residuals}
# Calculate standard deviation of residuals
test_resid_sd <- sd(pred_test$.resid)

HDD_future <- HDD_future %>%
    mutate(
        lo.95 = HDD_QTY - 1.96 * test_resid_sd,
        lo.80 = HDD_QTY - 1.28 * test_resid_sd,
        hi.80 = HDD_QTY + 1.28 * test_resid_sd,
        hi.95 = HDD_QTY + 1.96 * test_resid_sd
        )
```

```{r plotting the forecast with the prediction intervals}
HDD_Quarterly %>%
    ggplot(aes(x = date, y = HDD_QTY)) +
    geom_point(alpha = 0.5, color = palette_light()[[1]]) + geom_line() +
    geom_ribbon(aes(ymin = lo.95, ymax = hi.95), data = HDD_future, 
                fill = "#D5DBFF", color = NA, size = 0) +
    geom_ribbon(aes(ymin = lo.80, ymax = hi.80, fill = key), data = HDD_future,
                fill = "#596DD5", color = NA, size = 0, alpha = 0.8) +
    geom_point(aes(x = date, y = HDD_QTY), data = HDD_future,
               alpha = 0.5, color = palette_light()[[2]]) +
    geom_line(aes(x = date, y = HDD_QTY), data = HDD_future, color = "white") + 
    labs(title = "HDD Quarterly Demand: 6-Month Forecast with Prediction Intervals",x = "Fiscal Date",y='Quarterly Demand') +
    theme_tq()
```

### Parting Thoughts
*Forecasting using the time series signature can be very accurate especially when time-based patterns are present in the underlying data. As with most machine learning applications, the prediction is only as good as the patterns in the data. Forecasting using this approach may not be suitable when patterns are not present or when the future is highly uncertain (i.e. past is not a suitable predictor of future performance). However, in may situations the time series signature can provide an accurate forecast.

One benefit to the machine learning approach that was not covered in this vignette but is an significant advantage is that other features (including non-time-based) can be included in the analysis if the values are present in the training and test sets and can be determined with some level of accuracy in the future. The beauty of this method is these features can easily be incorporated into the model and prediction.

Last, a few points on the modeling process. Important modeling steps such as pre-processing data, removing correlated features, and so on where not addressed or included in this vignette. The astute modeler would certainly review the data and processing accordingly to achieve an optimal model.*
